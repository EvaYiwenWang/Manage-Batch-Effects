[
["index.html", "Managing Batch Effects in Microbiome Data Chapter 1 Examples of microbiome studies with batch effects 1.1 Study description 1.2 Data processing", " Managing Batch Effects in Microbiome Data Yiwen Wang, Kim-Anh Lê Cao 2019-10-22 Chapter 1 Examples of microbiome studies with batch effects This vignette provides all the analyses performed in the paper ‘Managing Batch Effects in Microbiome Data’ by Yiwen Wang and Kim-Anh Lê Cao. Packages installation and loading First, you will need to install then load the following packages from the CRAN and Bioconductor: # cran.packages &lt;- c(&#39;knitr&#39;, &#39;mixOmics&#39;, &#39;xtable&#39;, &#39;ggplot2&#39;, &#39;vegan&#39;, &#39;cluster&#39;, # &#39;gridExtra&#39;, &#39;pheatmap&#39;, &#39;ruv&#39;, &#39;lmerTest&#39;, &#39;bapred&#39;) # install.packages(cran.packages) # bioconductor.packages &lt;- c(&#39;sva&#39;, &#39;limma&#39;, &#39;AgiMicroRna&#39;, # &#39;variancePartition&#39;, &#39;pvca&#39;) # if (!requireNamespace(&#39;BiocManager&#39;, quietly = TRUE)) # install.packages(&#39;BiocManager&#39;) # BiocManager::install(bioconductor.packages, version = &#39;3.8&#39;) library(knitr) library(xtable) # table library(mixOmics) library(sva) # ComBat library(ggplot2) # PCA sample plot with density library(gridExtra) # PCA sample plot with density library(limma) # removeBatchEffect (LIMMA) library(vegan) # RDA library(AgiMicroRna) # RLE plot library(cluster) # silhouette coefficient library(variancePartition) # variance calculation library(pvca) # PVCA library(pheatmap) # heatmap library(ruv) # RUVIII library(lmerTest) # lmer library(bapred) # FAbatch 1.1 Study description 1.1.1 Sponge Aplysina aerophoba study Sacristán-Soriano et al. studied the potential involvement of bacterial communities from the sponge species A. aerophoba in the biosynthesis of brominated alkaloids (BAs) (Sacristán-Soriano et al. 2011). They compared the microbial composition and BA concentration in two different tissues (ectosome and choanosome) to investigate the relationship between bacterial composition and BA concentration. The authors concluded that differences in bacterial profiles were not only due to tissue variation (the main effect of interest), but also because the samples were run on two separate denaturing gradient gels during processing. Gel thus acted as a technical batch effect as described in Table 1 below. Table 1. Overview of exemplar datasets with batch effects. We considered microbiome studies from sponge Aplysina aerophoba; organic matter in anaerobic digestion (AD) and mice models with Huntington’s disease (HD). 1.1.2 Anaerobic digestion study Anaerobic Digestion (AD) is a microbiological process of organic matter degradation that produces a biogas used in electrical and thermal energy production. However, the AD bioprocess undergoes inhibition during its developmental stage that is not well characterised: Chapleur et al. explored microbial indicators that could improve the AD bioprocess’s efficacy and prevent its failure (Chapleur et al. 2016). They profiled the microbiota of 75 AD samples in various conditions. Here we consider two different ranges of phenol concentration as treatments. The experiment was conducted at different dates (5), which constitutes a technical source of unwanted variation (Table 1). 1.1.3 Huntington’s disease study In their study, Kong et al. reported differences in microbial composition between Huntington’s disease (HD) and wild-type (WT) mice (Kong et al. 2018). However, the establishment of microbial communities was also driven by biological batch effects: the cage environment and sex. Here we consider only female mice to illustrate a special case of a batch \\(\\times\\) treatment unbalanced design. The HD data include 13 faecal mice samples hosted across 4 cages (Table 1). We load the data and functions that are provided outside the packages. # load the data load(file = &#39;./datasets/microbiome_datasets.RData&#39;) # load the extra functions source(file = &#39;./Functions.R&#39;) dim(sponge.tss) ## [1] 32 24 dim(ad.count) ## [1] 75 567 dim(hd.count) ## [1] 13 368 Note: the AD data and HD data loaded are raw counts, while sponge data are total sum scaling (TSS) scaled data calculated on raw counts, with no offset. 1.2 Data processing Here are the processing steps for the raw count microbiome data: Prefilter the count data to remove features with excess zeroes across all samples Add an offset of 1 to the whole data matrix — note that this is not ideal but provides a pracitical way to handle zero counts. Log-ratio transformation with Centered Log Ratio (CLR) 1.2.1 Prefiltering We use a prefiltering step to remove OTUs for which the sum of counts are below a set threshold (0.01%) compared to the total sum of all counts (Arumugam et al. 2011). # ad data ad.index.keep &lt;- which(colSums(ad.count)*100/(sum(colSums(ad.count))) &gt; 0.01) ad.count.keep &lt;- ad.count[, ad.index.keep] dim(ad.count.keep) ## [1] 75 231 # hd data hd.count.keep &lt;- hd.count dim(hd.count.keep) ## [1] 13 368 Note: The HD data only include 13 samples, which are a small part of a big dataset that has already been prefiltered. We retained all the OTUs in the data and did not redo the prefiltering again. 1.2.2 Adding offset We need to add an offset of 1 to all count data to handle zeroes for the CLR transformation. As the sponge data were TSS scaled, a small offset is added in this specific case. According to scale invariance principle (Aitchison 1986), it returns the same results with CLR transformation on raw counts or TSS data. However, we recommend starting from the raw counts (not TSS) for those analyses. # sponge data sponge.tss &lt;- sponge.tss + 0.01 # ad data ad.count.keep &lt;- ad.count.keep + 1 # hd data hd.count.keep &lt;- hd.count.keep + 1 1.2.3 Centered log-ratio transformation Microbiome data are compostional and with different library sizes. Using standard statistical methods on such data may lead to spurious results and therefore the data must be further transformed. The CLR is the transformation of choice. # sponge data sponge.tss.clr &lt;- logratio.transfo(sponge.tss, logratio = &#39;CLR&#39;) class(sponge.tss.clr) &lt;- &#39;matrix&#39; # ad data ad.clr &lt;- logratio.transfo(ad.count.keep, logratio = &#39;CLR&#39;) class(ad.clr) &lt;- &#39;matrix&#39; # hd data hd.clr &lt;- logratio.transfo(hd.count.keep, logratio = &#39;CLR&#39;) class(hd.clr) &lt;- &#39;matrix&#39; The final CLR data of sponge study, AD study and HD study contain 32 samples and 24 OTUs, 75 samples and 231 OTUs, 13 samples and 368 OTUs, respectively as described in Table 1. Bibliography "],
["detect.html", "Chapter 2 Batch effect detection 2.1 Principal component analysis (PCA) with density plot per component 2.2 Density plot and box plot 2.3 RLE plots 2.4 Heatmap", " Chapter 2 Batch effect detection In this chapter, we apply qualitative methods and diagnostic plots to visually assess the presence of batch effects. 2.1 Principal component analysis (PCA) with density plot per component PCA is an unsupervised method used to explore the data variance structure by reducing its dimensions to a few principal components (PC) that explain the greatest variation in the data. Density plots are a complementary way to visualise batch effects per PC through examining the distributions of all samples. First, we run a good old PCA on the data, to assess whether major sources of variation can be explained by batch effects: in cases where batch effects account for a large source of variation in the data, the scatter plot of the top PCs should highlight a separation of the samples due to different batches. Plotting density plots on each component helps to visualise whether it is the case: samples within a batch will show similar distributions, and samples across different batches will show different distributions, if there is a batch effect. # sponge data sponge.pca.before &lt;- pca(sponge.tss.clr, ncomp = 3) # ad data ad.pca.before &lt;- pca(ad.clr, ncomp = 3) # hd data hd.pca.before &lt;- pca(hd.clr, ncomp = 3) # sponge data Scatter_Density(data = sponge.pca.before$variates$X, batch = sponge.batch, trt = sponge.trt, expl.var = sponge.pca.before$explained_variance, xlim = c(-4.5,5), ylim = c(-3,4), batch.legend.title = &#39;Gel (batch)&#39;, trt.legend.title = &#39;Tissue (trt)&#39;, title = &#39;Before batch effect correction (Sponge)&#39;) In sponge data, the first PC (explaining the largest source of variation) shows variation between samples from different tissues (the effect of interest), while the second PC (explaining the second largest source of variation) displays sample differences due to different batches, as also highlighted in the density plots per component. Therefore, PCA plots can inform not only of the presence of batch effects, but also which variation is the largest in the data. In this particular dataset, the effect of interest variation is larger than batch variation. # ad data Scatter_Density(data = ad.pca.before$variates$X, batch = ad.batch, trt = ad.trt, expl.var = ad.pca.before$explained_variance, xlim = c(-15,14), ylim = c(-13,14), batch.legend.title = &#39;Date (batch)&#39;, trt.legend.title = &#39;Conc (trt)&#39;, title = &#39;Before batch effect correction (AD)&#39;) In AD data, we observe a separation of samples from batch 14/04/2016. The batch variation is mostly explained by the second PC. # hd data Scatter_Density(data = hd.pca.before$variates$X, batch = hd.batch, trt = hd.trt, expl.var = hd.pca.before$explained_variance, xlim = c(-20,20), ylim = c(-25,15), batch.legend.title = &#39;Cage (batch)&#39;, trt.legend.title = &#39;Genotype (trt)&#39;, title = &#39;Before batch effect correction (HD)&#39;) In HD data, batch effect is due to different cages and obvious. The batch variation is both explained by the first and second PC. 2.2 Density plot and box plot For non systematic batch effects, it is useful to visualise a few OTUs individually. We apply density plots and box plots on OTUs, one at a time from each dataset to visualise batch effects. But only one OTU each dataset is selected as examples. We randomly select OTU9 in sponge data, and generate density plots and box plots separately across samples within each batch to observe whether batch effects serve as a major source of variation. # sponge data sponge.before.df &lt;- data.frame(value = sponge.tss.clr[,9], batch = sponge.batch) box_plot_fun(data = sponge.before.df, x = sponge.before.df$batch, y = sponge.before.df$value, title = &#39;OTU9 (Sponge)&#39;, batch.legend.title = &#39;Gel (batch)&#39;) ggplot(sponge.before.df, aes(x = value, fill = batch)) + geom_density(alpha = 0.5) + scale_fill_manual(values = color.mixo(1:10)) + labs(title = &#39;OTU9 (Sponge)&#39;, x = &#39;Value&#39;, fill = &#39;Gel (batch)&#39;) + theme_bw() + theme(plot.title = element_text(hjust = 0.5), panel.grid = element_blank()) For the proportional abundance of OTU9, the samples within different batches are very distinct, indicating a strong batch effect in sponge data. Assuming the data fit the distribution of the linear model (which is the case here after CLR transformation), we can also assess the effect of batch in a linear model on that particular OTU9: sponge.lm &lt;- lm(sponge.tss.clr[,9] ~ sponge.trt + sponge.batch) summary(sponge.lm) ## ## Call: ## lm(formula = sponge.tss.clr[, 9] ~ sponge.trt + sponge.batch) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.87967 -0.24705 0.04588 0.24492 1.00757 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.7849 0.1497 11.922 1.06e-12 *** ## sponge.trtE 0.1065 0.1729 0.616 0.543 ## sponge.batch2 -0.7910 0.1729 -4.575 8.24e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.489 on 29 degrees of freedom ## Multiple R-squared: 0.4236, Adjusted R-squared: 0.3839 ## F-statistic: 10.66 on 2 and 29 DF, p-value: 0.0003391 The batch (gel) effect is statistically significant (P \\(&lt;\\) 0.001), as indicated in the sponge.batch2 row. # ad data ad.before.df &lt;- data.frame(value = ad.clr[,1], batch = ad.batch) box_plot_fun(data = ad.before.df,x = ad.before.df$batch, y = ad.before.df$value, title = &#39;OTU12 (AD)&#39;, batch.legend.title = &#39;Date (batch)&#39;, x.angle = 45, x.hjust = 1) ggplot(ad.before.df, aes(x = value, fill = batch)) + geom_density(alpha = 0.5) + scale_fill_manual(values = color.mixo(1:10)) + labs(title = &#39;OTU12 (AD)&#39;,x = &#39;Value&#39;,fill = &#39;Date (batch)&#39;) + theme_bw() + theme(plot.title = element_text(hjust = 0.5), panel.grid = element_blank()) Batch effects in AD data are also easily visualised. ad.lm &lt;- lm(ad.clr[,1] ~ ad.trt + ad.batch) anova(ad.lm) ## Analysis of Variance Table ## ## Response: ad.clr[, 1] ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## ad.trt 1 1.460 1.4605 3.1001 0.08272 . ## ad.batch 4 32.889 8.2222 17.4532 6.168e-10 *** ## Residuals 69 32.506 0.4711 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 In AD data, the difference between batches (dates) is statistically significant (P &lt; 0.001, as tested with ANOVA). We can also obtain P values between each two batch categories. summary(ad.lm) ## ## Call: ## lm(formula = ad.clr[, 1] ~ ad.trt + ad.batch) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.09885 -0.39613 -0.00381 0.36645 1.98185 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.311213 0.247768 9.328 7.57e-14 *** ## ad.trt1-2 0.203619 0.171183 1.189 0.23833 ## ad.batch14/04/2016 -0.828100 0.287918 -2.876 0.00535 ** ## ad.batch01/07/2016 0.007239 0.273672 0.026 0.97897 ## ad.batch14/11/2016 0.062689 0.282978 0.222 0.82533 ## ad.batch21/09/2017 1.361132 0.306373 4.443 3.30e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.6864 on 69 degrees of freedom ## Multiple R-squared: 0.5138, Adjusted R-squared: 0.4786 ## F-statistic: 14.58 on 5 and 69 DF, p-value: 9.665e-10 # hd data hd.before.df &lt;- data.frame(value = hd.clr[,1], batch = hd.batch) box_plot_fun(data = hd.before.df, x = hd.before.df$batch, y = hd.before.df$value,title = &#39;OTU1 (HD)&#39;, batch.legend.title = &#39;Cage (batch)&#39;) ggplot(hd.before.df, aes(x = value, fill = batch)) + geom_density(alpha = 0.5) + scale_fill_manual(values = color.mixo(1:10)) + labs(title = &#39;OTU1 (HD)&#39;,x = &#39;Value&#39;,fill = &#39;Cage (batch)&#39;) + theme_bw() + theme(plot.title = element_text(hjust = 0.5), panel.grid = element_blank()) In HD data, we easily detect the differences between samples within different batches. hd.lm &lt;- lm(hd.clr[,1] ~ hd.batch) anova(hd.lm) ## Analysis of Variance Table ## ## Response: hd.clr[, 1] ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## hd.batch 3 2.4108 0.80359 5.2569 0.02276 * ## Residuals 9 1.3758 0.15286 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 As the batch x treatment design of HD data is nested and unbalanced, the linear model with both treatment (genotype) and batch (cage) is unable to fit. We therefore fit a linear model with batch effect only. The difference between cages is statistically significant (P &lt; 0.05). But the difference may also be influenced by treatment and we are unable to exclude treatment influence. 2.3 RLE plots RLE plots can be plotted using ‘RleMicroRna’ in R package ‘AgiMicroRna’. Here, we made some changes on the function ‘RleMicroRna’, called ‘RleMicroRna2’ and available on our extra functions ‘Functions.R’. RLE plots are based on the assumption that the majority of microbial variables are unaffected by the effect of interest, and therefore any sample heterogeneity observed - i.e. different distributions and their variances, and medians different from zero, should indicate the presence of batch effects. In our case studies, the treatment information is known, so we generate multiple RLE plots per treatment group, as suggested by (Lin et al. 2018). In sponge data, we group the samples according to the tissue (choanosome / ectosome) and generate two RLE plots: # sponge data sponge.batch_c &lt;- sponge.batch[sponge.trt == &#39;C&#39;] sponge.batch_e &lt;- sponge.batch[sponge.trt == &#39;E&#39;] sponge.before_c &lt;- sponge.tss.clr[sponge.trt == &#39;C&#39;, ] sponge.before_e &lt;- sponge.tss.clr[sponge.trt == &#39;E&#39;, ] RleMicroRna2(object = t(sponge.before_c), batch = sponge.batch_c, maintitle = &#39;Sponge (tissue: choanosome)&#39;) RleMicroRna2(object = t(sponge.before_e), batch = sponge.batch_e, maintitle = &#39;Sponge (tissue: ectosome)&#39;) For both RLE plots with samples from different tissues, the batch effect is not obvious as all medians of samples are close to zero, but Gel2 has a greater interquartile range (IQR) than the other samples. # ad data ad.batch_05 &lt;- ad.batch[ad.trt == &#39;0-0.5&#39;] ad.batch_2 &lt;- ad.batch[ad.trt == &#39;1-2&#39;] ad.before_05 &lt;- ad.clr[ad.trt == &#39;0-0.5&#39;, ] ad.before_2 &lt;- ad.clr[ad.trt == &#39;1-2&#39;, ] RleMicroRna2(object = t(ad.before_05), batch = ad.batch_05, maintitle = &#39;AD (initial phenol conc: 0-0.5 g/L)&#39;, legend.cex = 0.5) RleMicroRna2(object = t(ad.before_2), batch = ad.batch_2, maintitle = &#39;AD (initial phenol conc: 1-2 g/L)&#39;, cex.xaxis = 0.7, legend.cex = 0.5) In RLE plots for the AD data, the batch effect is also not obvious as all medians of samples are close to zero, but the samples dated 14/04/2016 may be affected by batch as they have a greater IQR than the other samples. # hd data hd.batch_h &lt;- hd.batch[hd.trt == &#39;HD&#39;] hd.batch_w &lt;- hd.batch[hd.trt == &#39;WT&#39;] hd.before_h &lt;- hd.clr[hd.trt == &#39;HD&#39;, ] hd.before_w &lt;- hd.clr[hd.trt == &#39;WT&#39;, ] RleMicroRna2(object = t(hd.before_h), batch = hd.batch_h, maintitle = &#39;HD (genotype: HD)&#39;) RleMicroRna2(object = t(hd.before_w), batch = hd.batch_w, maintitle = &#39;HD (genotype: WT)&#39;) The batch effect in HD data is not easily detected, but Cage G has a greater IQR than the other samples, which may indicate a batch effect. 2.4 Heatmap Clustering analysis can be used to detect batch effects. Ideally samples with the same treatment will be clustered together, data clustered by batches instead of treatments indicate a batch effect. Heatmaps and dendrograms are two common approaches to visualise the clusters. # Sponge data # scale on OTUs sponge.tss.clr.scale &lt;- scale(sponge.tss.clr, center = T, scale = T) # scale on samples sponge.tss.clr.scale &lt;- scale(t(sponge.tss.clr.scale), center = T, scale = T) sponge.anno_col &lt;- data.frame(Batch = sponge.batch, Tissue = sponge.trt) sponge.anno_metabo_colors &lt;- list(Batch = c(&#39;1&#39; = &#39;#388ECC&#39;, &#39;2&#39; = &#39;#F68B33&#39;), Tissue = c(C = &#39;#F0E442&#39;, E = &#39;#D55E00&#39;)) pheatmap(sponge.tss.clr.scale, scale = &#39;none&#39;, cluster_rows = F, cluster_cols = T, fontsize_row = 5, fontsize_col = 8, fontsize = 8, clustering_distance_rows = &#39;euclidean&#39;, clustering_method = &#39;ward.D&#39;, treeheight_row = 30, annotation_col = sponge.anno_col, annotation_colors = sponge.anno_metabo_colors, border_color = &#39;NA&#39;, main = &#39;Sponge data - Scaled&#39;) In sponge data, samples are preferentially clustered by batch instead of tissue type, indicating a batch effect. # AD data ad.clr.scale &lt;- scale(ad.clr,center = T, scale = T) ad.clr.scale &lt;- scale(t(ad.clr.scale), center = T, scale = T) ad.anno_col &lt;- data.frame(Batch = ad.batch, Treatment = ad.trt) ad.anno_metabo_colors &lt;- list(Batch = c(&#39;09/04/2015&#39; = &#39;#388ECC&#39;, &#39;14/04/2016&#39; = &#39;#F68B33&#39;, &#39;01/07/2016&#39; = &#39;#C2C2C2&#39;, &#39;14/11/2016&#39; = &#39;#009E73&#39;, &#39;21/09/2017&#39; = &#39;#CC79A7&#39;), Treatment = c(&#39;0-0.5&#39; = &#39;#0072B2&#39;, &#39;1-2&#39; = &#39;#999999&#39;)) pheatmap(ad.clr.scale, scale = &#39;none&#39;, cluster_rows = F, cluster_cols = T, fontsize_row = 4, fontsize_col = 6, fontsize = 8, clustering_distance_rows = &#39;euclidean&#39;, clustering_method = &#39;ward.D&#39;, treeheight_row = 30, annotation_col = ad.anno_col, annotation_colors = ad.anno_metabo_colors, border_color = &#39;NA&#39;, main = &#39;AD data - Scaled&#39;) In AD data, samples within batch 14/04/2016 are clustered and distinct from other samples, also indicating a batch effect. # HD data hd.clr.scale &lt;- scale(hd.clr,center = T, scale = T) hd.clr.scale &lt;- scale(t(hd.clr.scale), center = T, scale = T) hd.anno_col &lt;- data.frame(Batch = hd.batch, Treatment = hd.trt) hd.anno_metabo_colors &lt;- list(Batch = c(&#39;F&#39; = &#39;#388ECC&#39;, &#39;G&#39; = &#39;#F68B33&#39;, &#39;H&#39; = &#39;#C2C2C2&#39;, &#39;J&#39; = &#39;#009E73&#39;), Treatment = c(&#39;HD&#39; = &#39;#0072B2&#39;, &#39;WT&#39; = &#39;#999999&#39;)) pheatmap(hd.clr.scale, scale = &#39;none&#39;, cluster_rows = F, cluster_cols = T, fontsize_row = 4, fontsize_col = 6, fontsize = 8, clustering_distance_rows = &#39;euclidean&#39;, clustering_method = &#39;ward.D&#39;, treeheight_row = 30, annotation_col = hd.anno_col, annotation_colors = hd.anno_metabo_colors, border_color = &#39;NA&#39;, main = &#39;HD data - Scaled&#39;) The batch effect in HD data is not obvious in this heatmap, as we observe not clustering according to batch. Bibliography "],
["adjust.html", "Chapter 3 Batch effect adjustment 3.1 Accounting for batch effects 3.2 Correcting for batch effects", " Chapter 3 Batch effect adjustment 3.1 Accounting for batch effects Methods that account for batch effects estimate unknown batch effects through matrix decomposition and / or assign a known or estimated batch as a covariate with linear models. 3.1.1 Linear model and linear mixed model LM and LMM are suitable for known batch effects, and can consider batch x treatment interaction and deal with unbalanced batch x treatment design. But they are univariate and rely on a Gaussian likelihood assumption, which may not apply to zero-inflated microbiome data despite CLR transformation. We fit a linear model with effect of interest and batch effect for each OTU in both sponge and AD data. The P-value for the regression coefficient associated with the effect of interest in a linear model is then extracted and multiple testing corrected with “FDR”. # Sponge data sponge.trt_p &lt;- apply(sponge.tss.clr, 2, FUN = function(x){ res.lm &lt;- lm(x ~ sponge.trt + sponge.batch) summary.res &lt;- summary(res.lm) p &lt;- summary.res$coefficients[2,4] }) sponge.trt_adjp &lt;- p.adjust(sponge.trt_p, method = &#39;fdr&#39;) # AD data ad.trt_p &lt;- apply(ad.clr, 2, FUN = function(x){ res.lm &lt;- lm(x ~ ad.trt + ad.batch) summary.res &lt;- summary(res.lm) p &lt;- summary.res$coefficients[2,4] }) ad.trt_adjp &lt;- p.adjust(ad.trt_p, method = &#39;fdr&#39;) As the batch x treatment design of HD data is unbalaced, we fit a linear mixed model considering batch (cage) as random effects. # HD data hd.trt_p &lt;- apply(hd.clr, 2, FUN = function(x){ res.lmm &lt;- lmer(x ~ hd.trt + (1|hd.batch)) summary.res &lt;- summary(res.lmm) p &lt;- summary.res$coefficients[2,5] }) hd.trt_adjp &lt;- p.adjust(hd.trt_p, method = &#39;fdr&#39;) 3.1.2 SVA SVA can account for unknown batch effects, but is a univariate approach that relies on a Gaussian likelihood assumption and implicitly introduces a correlation between treatment and batch. The sva function performs two different steps. First it identifies the number of latent factors that need to be estimated. The number of factors can be estimated using the function num.sv. We first fit a full model with effect of interest and a null model with no effect, and use the full model in the function num.sv to estimate the number of latent factors. # sponge data sponge.mod &lt;- model.matrix( ~ sponge.trt) # full model sponge.mod0 &lt;- model.matrix( ~ 1,data = sponge.trt) # null model sponge.sva.n &lt;- num.sv(dat = t(sponge.tss.clr), mod = sponge.mod) Next we apply the sva function to estimate the surrogate variables with both full and null models: sponge.sva &lt;- sva(dat = t(sponge.tss.clr), mod = sponge.mod, mod0 = sponge.mod0, n.sv = sponge.sva.n) ## Number of significant surrogate variables is: 1 ## Iteration (out of 5 ):1 2 3 4 5 We then include the estimated surrogate variables in both the null and full models. The reason is that we want to adjust for the surrogate variables, so we treat them as adjustment variables that must be included in both models. The f.pvalue function is then used to calculate parametric F-test P-values and Q-values (adjusted P-values) for each OTU of sponge data. sponge.mod.bat &lt;- cbind(sponge.mod, sponge.sva$sv) sponge.mod0.bat &lt;- cbind(sponge.mod0, sponge.sva$sv) sponge.sva.trt_p &lt;- f.pvalue(t(sponge.tss.clr), sponge.mod.bat, sponge.mod0.bat) sponge.sva.trt_adjp &lt;- p.adjust(sponge.sva.trt_p, method=&#39;fdr&#39;) Now these P-values and Q-values are accounting for surrogate variables (estimated batch effects). We also apply SVA on both AD and HD data. # ad data ad.mod &lt;- model.matrix( ~ ad.trt) ad.mod0 &lt;- model.matrix( ~ 1, data = ad.trt) ad.sva.n &lt;- num.sv(dat = t(ad.clr), mod = ad.mod) ad.sva &lt;- sva(t(ad.clr), ad.mod, ad.mod0, n.sv = ad.sva.n) ## Number of significant surrogate variables is: 6 ## Iteration (out of 5 ):1 2 3 4 5 ad.mod.bat &lt;- cbind(ad.mod, ad.sva$sv) ad.mod0.bat &lt;- cbind(ad.mod0, ad.sva$sv) ad.sva.trt_p &lt;- f.pvalue(t(ad.clr), ad.mod.bat, ad.mod0.bat) ad.sva.trt_adjp &lt;- p.adjust(ad.sva.trt_p, method = &#39;fdr&#39;) # hd data hd.mod &lt;- model.matrix( ~ hd.trt) hd.mod0 &lt;- model.matrix( ~ 1,data = hd.trt) hd.sva.n &lt;- num.sv(dat = t(hd.clr), mod = hd.mod) hd.sva &lt;- sva(t(hd.clr), hd.mod, hd.mod0, n.sv = hd.sva.n) ## Number of significant surrogate variables is: 3 ## Iteration (out of 5 ):1 2 3 4 5 hd.mod.bat &lt;- cbind(hd.mod, hd.sva$sv) hd.mod0.bat &lt;- cbind(hd.mod0, hd.sva$sv) hd.sva.trt_p &lt;- f.pvalue(t(hd.clr), hd.mod.bat, hd.mod0.bat) hd.sva.trt_adjp &lt;- p.adjust(hd.sva.trt_p, method = &#39;fdr&#39;) 3.1.3 RUV2 RUV2 estimates and accounts for unknown batch effects, but the method requires negative control variables that are affected by batch effects but not treatment effects. Practically, negative control variables are chosen prior during the experimental design so that they are not affected by treatments (and assume they are affected by batch effects). RUV2 can only account for the difference captured by these controls. Since our three datasets do not have negative control variables, we use a linear model (or linear mixed model) to identify OTUs that are not affected by treatment, those will be considered as pseudo negative control variables to fit the assumptions of RUV2. The P-values of treatment effects calculated in section ‘linear model and linear mixed model’ are therefore used here. Note: This analysis is not optimal as we use pseudo negative control variables, but we wish to provide this as a practical example. # sponge data sponge.nc &lt;- sponge.trt_adjp &gt; 0.05 # AD data ad.nc &lt;- ad.trt_adjp &gt; 0.05 # HD data hd.nc &lt;- hd.trt_p &gt; 0.05 Note: In HD data, there is no OTU having statistically siginificant difference between genotypes. We use P-values instead of adjusted P-values to set the negative controls. We then apply the RUV2 function. This function needs to specify the number of unwanted factors (components of negative controls), which we arbitrarily set to k = 3. We then extract the P-values of treatment effects considering unwanted batch effects after FDR adjustment. # sponge data sponge.ruv2 &lt;- RUV2(Y = sponge.tss.clr, X = sponge.trt, ctl = sponge.nc, k = 3) # k is subjective sponge.ruv2.trt_p &lt;- sponge.ruv2$p sponge.ruv2.trt_adjp &lt;- p.adjust(sponge.ruv2.trt_p, method=&quot;fdr&quot;) # AD data ad.ruv2 &lt;- RUV2(Y = ad.clr, X = ad.trt, ctl = ad.nc, k = 3) # k is subjective ad.ruv2.trt_p &lt;- ad.ruv2$p ad.ruv2.trt_adjp &lt;- p.adjust(ad.ruv2.trt_p, method=&quot;fdr&quot;) # HD data hd.ruv2 &lt;- RUV2(Y = hd.clr, X = hd.trt, ctl = hd.nc, k = 3) # k is subjective hd.ruv2.trt_p &lt;- hd.ruv2$p hd.ruv2.trt_adjp &lt;- p.adjust(hd.ruv2.trt_p, method=&quot;fdr&quot;) 3.1.4 RUV4 RUV4 is an updated version of RUV2 that uses negative control variables and the residual matrix that has no treatment effect to estimate unwanted batch effects. RUV4 also requires to specify the number of unwanted factors as RUV2, which we estimate with the function ‘getK’ (from the ruv package). This function is only for RUV4 and the estimated k is not always suitable. If the estimated k is 0, k can be set to 1 instead to account for unwanted variation captured from negative controls. # sponge data sponge.k.obj &lt;- getK(Y = sponge.tss.clr, X = sponge.trt, ctl = sponge.nc) sponge.k &lt;- sponge.k.obj$k sponge.k &lt;- ifelse(sponge.k !=0, sponge.k, 1) sponge.ruv4 &lt;- RUV4(Y = sponge.tss.clr, X = sponge.trt, ctl = sponge.nc, k = sponge.k) sponge.ruv4.trt_p &lt;- sponge.ruv4$p sponge.ruv4.trt_adjp &lt;- p.adjust(sponge.ruv4.trt_p, method=&quot;fdr&quot;) # AD data ad.k.obj &lt;- getK(Y = ad.clr, X = ad.trt, ctl = ad.nc) ad.k &lt;- ad.k.obj$k ad.k &lt;- ifelse(ad.k !=0, ad.k, 1) ad.ruv4 &lt;- RUV4(Y = ad.clr, X = ad.trt, ctl = ad.nc, k = ad.k) ad.ruv4.trt_p &lt;- ad.ruv4$p ad.ruv4.trt_adjp &lt;- p.adjust(ad.ruv4.trt_p, method=&quot;fdr&quot;) # HD data hd.k.obj &lt;- getK(Y = hd.clr, X = hd.trt, ctl = hd.nc) hd.k &lt;- hd.k.obj$k hd.k &lt;- ifelse(hd.k !=0, hd.k, 1) hd.ruv4 &lt;- RUV4(Y = hd.clr, X = hd.trt, ctl = hd.nc, k = hd.k) hd.ruv4.trt_p &lt;- hd.ruv4$p hd.ruv4.trt_adjp &lt;- p.adjust(hd.ruv4.trt_p, method=&quot;fdr&quot;) 3.2 Correcting for batch effects An alternative approach to manage batch effects is to remove batch effects from the original microbiome data, then use the corrected data in any subsequent data analysis. Compared with methods accounting for batch effects, batch effect correction methods are practical and enable broader application in a variety of analyses. However, the methods do not consider the correlation (linear) and interaction (non-linear) between batch and treatment effects and may result in over-adjusted batch effects, statistical power loss, and an inability to detect variables associated with the treatment effect. 3.2.1 BMC (batch mean centering) We center data within a batch across all variables. As a result, each batch mean is standardised to zero. BMC has several disadvantages: it is a univariate method and it is not optimal for non-Gaussian distributed microbiome data. # Sponge data sponge.b1 &lt;- scale(sponge.tss.clr[sponge.batch == 1, ], center = TRUE, scale = FALSE) sponge.b2 &lt;- scale(sponge.tss.clr[sponge.batch == 2, ], center = TRUE, scale = FALSE) sponge.bmc &lt;- rbind(sponge.b1, sponge.b2) sponge.bmc &lt;- sponge.bmc[rownames(sponge.tss.clr), ] # AD data ad.b1 &lt;- scale(ad.clr[ad.batch == &#39;09/04/2015&#39;, ], center = TRUE, scale = FALSE) ad.b2 &lt;- scale(ad.clr[ad.batch == &#39;14/04/2016&#39;, ], center = TRUE, scale = FALSE) ad.b3 &lt;- scale(ad.clr[ad.batch == &#39;14/11/2016&#39;, ], center = TRUE, scale = FALSE) ad.b4 &lt;- scale(ad.clr[ad.batch == &#39;01/07/2016&#39;, ], center = TRUE, scale = FALSE) ad.b5 &lt;- scale(ad.clr[ad.batch == &#39;21/09/2017&#39;, ], center = TRUE, scale = FALSE) ad.bmc &lt;- rbind(ad.b1, ad.b2, ad.b3, ad.b4, ad.b5) ad.bmc &lt;- ad.bmc[rownames(ad.clr), ] 3.2.2 ComBat ComBat requires known and systematic batch effects. If the treatment information is known, the option mod can be fitted with a full model having treatment informationn to efficiently maintain enough treatment variation (see examples below for sponge and AD data). The mod can also be NULL if the treatment information is unknown. # Sponge data sponge.combat &lt;- t(ComBat(t(sponge.tss.clr), batch = sponge.batch, mod = sponge.mod, par.prior = F, prior.plots = F)) ## Found2batches ## Adjusting for1covariate(s) or covariate level(s) ## Standardizing Data across genes ## Fitting L/S model and finding priors ## Finding nonparametric adjustments ## Adjusting the Data # AD data ad.combat &lt;- t(ComBat(t(ad.clr), batch = ad.batch, mod = ad.mod, par.prior = F, prior.plots = F)) ## Found5batches ## Adjusting for1covariate(s) or covariate level(s) ## Standardizing Data across genes ## Fitting L/S model and finding priors ## Finding nonparametric adjustments ## Adjusting the Data 3.2.3 removeBatchEffect removeBatchEffect is a function implemented in the LIMMA package that fits a linear model for each variable given a series of conditions as explanatory variables, including the batch effect and treatment effect. Contrary to a standard linear or linear mixed models (see section ‘linear model and linear mixed model’) that simultaneously estimate treatment and batch effects, removeBatchEffect subtracts the batch effect from the original data, resulting in a residual matrix that contains any and only treatment effect. The option design is the same as option mod in ComBat. # Sponge data sponge.limma &lt;- t(removeBatchEffect(t(sponge.tss.clr), batch = sponge.batch, design = sponge.mod)) ad.limma &lt;- t(removeBatchEffect(t(ad.clr), batch = ad.batch, design = ad.mod)) 3.2.4 FAbatch FAbatch is a combination of location-scale adjustment and factor analysis. We fit y with the treatment information and batch with batch information. Since this method only accepts numeric variables, the levels of variables are changed to be numeric (e.g. ‘1’, ‘2’ and so on). However, on our example, FAbatch did not converge, potentially leading to suboptimal results. We therefore did not compare the results from FAbatch with those from other methods. # sponge data sponge.fabatch.obj &lt;- fabatch(x = sponge.tss.clr, y = as.factor(as.numeric(sponge.trt)), batch = sponge.batch) sponge.fabatch &lt;- sponge.fabatch.obj$xadj # ad data ad.fabatch.obj &lt;- fabatch(x = ad.clr, y = as.factor(as.numeric(ad.trt)), batch = as.factor(as.numeric(ad.batch))) ad.fabatch &lt;- ad.fabatch.obj$xadj 3.2.5 Percentile normalisation Percentile normalisation (PN) was developed for microbiome data integration. For each batch, it transforms the relative abundance of control samples to their own percentiles while converting the relative abundance of case samples into the percentiles of their corresponding control distribution. The method thus only applies to case-control studies, and may lose a large amount of information as it uses percentiles rather than the original values. Note: PN applies on TSS scaled data (Gibbons, Duvallet, and Alm 2018). As we added an offset on sponge TSS scaled data, we re-applied the TSS. # sponge data sponge.tss &lt;- t(apply(sponge.tss, 1, function(x){x/sum(x)})) sponge.percentile &lt;- percentile_norm(data = sponge.tss, batch = sponge.batch, trt = sponge.trt) # ad data # TSS ad.tss &lt;- t(apply(ad.count.keep, 1, function(x){x/sum(x)})) ad.percentile &lt;- percentile_norm(data = ad.tss, batch = ad.batch, trt = ad.trt) 3.2.6 SVD-based method We center and scale the data before SVD. After SVD, we deflate the first component, which has the highest variation and is assumed to be related to batch effects. # sponge data sponge.sd &lt;- apply(sponge.tss.clr, 2, sd) # calculate standard deviation sponge.mean &lt;- apply(sponge.tss.clr, 2, mean) # calculate mean sponge.X &lt;- scale(sponge.tss.clr, center = T, scale = T) # center and scale sponge.m &lt;- crossprod(sponge.X) # generate a square matrix sponge.m.svd &lt;- svd(sponge.m) # SVD # barplot(sponge.m.svd$d) # extract 1st singular vectors sponge.a1 &lt;- sponge.m.svd$u[ ,1] sponge.b1 &lt;- sponge.m.svd$v[ ,1] # deflate component 1 from the data sponge.t1 &lt;- sponge.X %*% sponge.a1 / drop(sqrt(crossprod(sponge.a1))) sponge.c1 &lt;- crossprod(sponge.X, sponge.t1) / drop(crossprod(sponge.t1)) sponge.svd.defl.matrix1 &lt;- sponge.X - sponge.t1 %*% t(sponge.c1) # add back mean and standard deviation sponge.svd &lt;- sponge.svd.defl.matrix1 sponge.svd[1:nrow(sponge.svd), 1:ncol(sponge.svd)] = NA for(i in 1:ncol(sponge.svd.defl.matrix1)){ for(j in 1:nrow(sponge.svd.defl.matrix1)){ sponge.svd[j,i] = sponge.svd.defl.matrix1[j,i]*sponge.sd[i] + sponge.mean[i] } } # ad data ad.sd &lt;- apply(ad.clr, 2, sd) # calculate standard deviation ad.mean &lt;- apply(ad.clr, 2, mean) # calculate mean ad.X &lt;- scale(ad.clr,center = T, scale = T) # center and scale ad.m &lt;- crossprod(ad.X) # generate a square matrix ad.m.svd &lt;- svd(ad.m) # SVD # barplot(ad.m.svd$d) # extract 1st singular vectors ad.a1 &lt;- ad.m.svd$u[ ,1] ad.b1 &lt;- ad.m.svd$v[ ,1] # deflate component 1 from the data ad.t1 &lt;- ad.X %*% ad.a1 / drop(sqrt(crossprod(ad.a1))) ad.c1 &lt;- crossprod(ad.X, ad.t1) / drop(crossprod(ad.t1)) ad.svd.defl.matrix1 &lt;- ad.X - ad.t1 %*% t(ad.c1) # add back mean and standard deviation ad.svd &lt;- ad.svd.defl.matrix1 ad.svd[1:nrow(ad.svd), 1:ncol(ad.svd)] = NA for(i in 1:ncol(ad.svd.defl.matrix1)){ for(j in 1:nrow(ad.svd.defl.matrix1)){ ad.svd[j,i] = ad.svd.defl.matrix1[j,i]*ad.sd[i] + ad.mean[i] } } 3.2.7 RUVIII RUVIII needs not only negative control variables as RUV2 and RUV4, but also technical sample replicates. As only AD data include sample replicates, we illustrate RUVIII on these data only. In contrast to RUV2 and RUV4, RUVIII is a multivariate method that accounts for the dependency between microbial variables, but it is currently limited to the correction of technical and computational sources of batch effects. Note: RUVIII requires the number of negative control variables to be larger than the sample size in order to fully use the sample information. # ad data only ad.replicates &lt;- ad.metadata$sample_name.data.extraction ad.replicates.matrix &lt;- replicate.matrix(ad.replicates) ad.ruvIII &lt;- RUVIII(Y = ad.clr, M = ad.replicates.matrix, ctl = ad.nc) rownames(ad.ruvIII) &lt;- rownames(ad.clr) Bibliography "],
["eval.html", "Chapter 4 Methods evaluation 4.1 Diagnostic plots 4.2 Variance calculation", " Chapter 4 Methods evaluation After batch effect adjustment, it is essential to evaluate its effectiveness. For simplicity, we focus only on strategies to assess batch effect correction methods, as methods that account for the batch effect often imply it has been assessed internally in the statistical model. 4.1 Diagnostic plots Diagnostic plots are useful to visually evaluate for post-correction batch effects, as presented earlier in section ‘batch effect detection’. 4.1.1 Principal component analysis (PCA) with density plot per component We apply PCA on both sponge and AD data before and after correction with different methods. # sponge data sponge.pca.before &lt;- pca(sponge.tss.clr, ncomp = 3) sponge.pca.bmc &lt;- pca(sponge.bmc, ncomp = 3) sponge.pca.combat &lt;- pca(sponge.combat, ncomp = 3) sponge.pca.limma &lt;- pca(sponge.limma, ncomp = 3) sponge.pca.percentile &lt;- pca(sponge.percentile, ncomp = 3) sponge.pca.svd &lt;- pca(sponge.svd, ncomp = 3) # ad data ad.pca.before &lt;- pca(ad.clr, ncomp = 3) ad.pca.bmc &lt;- pca(ad.bmc, ncomp = 3) ad.pca.combat &lt;- pca(ad.combat, ncomp = 3) ad.pca.limma &lt;- pca(ad.limma, ncomp = 3) ad.pca.percentile &lt;- pca(ad.percentile, ncomp = 3) ad.pca.svd &lt;- pca(ad.svd, ncomp = 3) ad.pca.ruv &lt;- pca(ad.ruvIII, ncomp = 3) We then plot these PCA sample plots with denisty plots per PC. Note: BMC: batch mean centering; PN: percentile normalisation; rBE: removeBatchEffect; SVD: singular value decomposition grid.arrange(sponge.pca.plot.before, sponge.pca.plot.bmc, sponge.pca.plot.combat, sponge.pca.plot.limma, ncol = 2) grid.arrange(sponge.pca.plot.before, sponge.pca.plot.percentile, sponge.pca.plot.svd, ncol = 2) In sponge data, SVD performed the worse, compared to BMC, removeBatchEffect and percentile normalisation, as it did not remove batch effects but removed tissue variation instead. grid.arrange(ad.pca.plot.before, ad.pca.plot.bmc, ad.pca.plot.combat, ad.pca.plot.limma, ncol = 2) grid.arrange(ad.pca.plot.before, ad.pca.plot.percentile, ad.pca.plot.svd, ad.pca.plot.ruv, ncol = 2) In AD data, BMC, removeBatchEffect, percentile normalisation and RUVIII removed the batch effects, and maintained the treatment effects. SVD did not removed the batch effect but decreased the treatment effects. 4.1.2 Density plot and box plot # sponge data sponge.before.df &lt;- data.frame(value = sponge.tss.clr[ ,9], batch = sponge.batch) sponge.boxplot.before &lt;- box_plot_fun(data = sponge.before.df, x = sponge.before.df$batch, y = sponge.before.df$value, title = &#39;OTU9 - before (Sponge)&#39;, batch.legend.title = &#39;Gel (batch)&#39;) sponge.bmc.df &lt;- data.frame(value = sponge.bmc[ ,9], batch = sponge.batch) sponge.boxplot.bmc &lt;- box_plot_fun(data = sponge.bmc.df, x = sponge.bmc.df$batch, y = sponge.bmc.df$value, title = &#39;OTU9 - BMC (Sponge)&#39;, batch.legend.title = &#39;Gel (batch)&#39;) sponge.combat.df &lt;- data.frame(value = sponge.combat[ ,9], batch = sponge.batch) sponge.boxplot.combat &lt;- box_plot_fun(data = sponge.combat.df, x = sponge.combat.df$batch, y = sponge.combat.df$value, title = &#39;OTU9 - ComBat (Sponge)&#39;, batch.legend.title = &#39;Gel (batch)&#39;) sponge.limma.df &lt;- data.frame(value = sponge.limma[ ,9], batch = sponge.batch) sponge.boxplot.limma &lt;- box_plot_fun(data = sponge.limma.df, x = sponge.limma.df$batch, y = sponge.limma.df$value, title = &#39;OTU9 - rBE(Sponge)&#39;, batch.legend.title = &#39;Gel (batch)&#39;) sponge.percentile.df &lt;- data.frame(value = sponge.percentile[ ,9], batch = sponge.batch) sponge.boxplot.percentile &lt;- box_plot_fun(data = sponge.percentile.df, x = sponge.percentile.df$batch, y = sponge.percentile.df$value, title = &#39;OTU9 - PN (Sponge)&#39;, batch.legend.title = &#39;Gel (batch)&#39;) sponge.svd.df &lt;- data.frame(value = sponge.svd[ ,9], batch = sponge.batch) sponge.boxplot.svd &lt;- box_plot_fun(data = sponge.svd.df, x = sponge.svd.df$batch, y = sponge.svd.df$value, title = &#39;OTU9 - SVD (Sponge)&#39;, batch.legend.title = &#39;Gel (batch)&#39;) grid.arrange(sponge.boxplot.before, sponge.boxplot.bmc, sponge.boxplot.combat, sponge.boxplot.limma, ncol = 2) grid.arrange(sponge.boxplot.before, sponge.boxplot.percentile, sponge.boxplot.svd, ncol = 2) From the boxplots of OTU9 in sponge data, the difference between two batches are removed by BMC, ComBat, removeBatchEffect and percentile normalisation correction. Among these methods, percentile normalisation does not remove as much batch difference as the other methods. # density plot # before sponge.dens.before &lt;- ggplot(sponge.before.df, aes(x = value, fill = batch)) + geom_density(alpha = 0.5) + scale_fill_manual(values = color.mixo(1:10)) + labs(title = &#39;OTU9 - before (Sponge)&#39;, x = &#39;Value&#39;, fill = &#39;Gel (batch)&#39;) + theme_bw() + theme(plot.title = element_text(hjust = 0.5), panel.grid = element_blank()) # BMC sponge.dens.bmc &lt;- ggplot(sponge.bmc.df, aes(x = value, fill = batch)) + geom_density(alpha = 0.5) + scale_fill_manual(values = color.mixo(1:10)) + labs(title = &#39;OTU9 - BMC (Sponge)&#39;, x = &#39;Value&#39;, fill = &#39;Gel (batch)&#39;) + theme_bw() + theme(plot.title = element_text(hjust = 0.5), panel.grid = element_blank()) # ComBat sponge.dens.combat &lt;- ggplot(sponge.combat.df, aes(x = value, fill = batch)) + geom_density(alpha = 0.5) + scale_fill_manual(values = color.mixo(1:10)) + labs(title = &#39;OTU9 - ComBat (Sponge)&#39;, x = &#39;Value&#39;, fill = &#39;Gel (batch)&#39;) + theme_bw() + theme(plot.title = element_text(hjust = 0.5), panel.grid = element_blank()) # removeBatchEffect sponge.dens.limma &lt;- ggplot(sponge.limma.df, aes(x = value, fill = batch)) + geom_density(alpha = 0.5) + scale_fill_manual(values = color.mixo(1:10)) + labs(title = &#39;OTU9 - rBE (Sponge)&#39;, x = &#39;Value&#39;, fill = &#39;Gel (batch)&#39;) + theme_bw() + theme(plot.title = element_text(hjust = 0.5), panel.grid = element_blank()) # percentile normal sponge.dens.percentile &lt;- ggplot(sponge.percentile.df, aes(x = value, fill = batch)) + geom_density(alpha = 0.5) + scale_fill_manual(values = color.mixo(1:10)) + labs(title = &#39;OTU9 - PN (Sponge)&#39;, x = &#39;Value&#39;, fill = &#39;Gel (batch)&#39;) + theme_bw() + theme(plot.title = element_text(hjust = 0.5), panel.grid = element_blank()) # SVD sponge.dens.svd &lt;- ggplot(sponge.svd.df, aes(x = value, fill = batch)) + geom_density(alpha = 0.5) + scale_fill_manual(values = color.mixo(1:10)) + labs(title = &#39;OTU9 - SVD (Sponge)&#39;, x = &#39;Value&#39;, fill = &#39;Gel (batch)&#39;) + theme_bw() + theme(plot.title = element_text(hjust = 0.5), panel.grid = element_blank()) grid.arrange(sponge.dens.before, sponge.dens.bmc, sponge.dens.combat, sponge.dens.limma, ncol = 2) grid.arrange(sponge.dens.before, sponge.dens.percentile, sponge.dens.svd, ncol = 2) We can also assess the effect of batch in a linear model before and after batch correction. # P-values sponge.lm.before &lt;- lm(sponge.tss.clr[ ,9] ~ sponge.trt + sponge.batch) summary(sponge.lm.before) ## ## Call: ## lm(formula = sponge.tss.clr[, 9] ~ sponge.trt + sponge.batch) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.87967 -0.24705 0.04588 0.24492 1.00757 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.7849 0.1497 11.922 1.06e-12 *** ## sponge.trtE 0.1065 0.1729 0.616 0.543 ## sponge.batch2 -0.7910 0.1729 -4.575 8.24e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.489 on 29 degrees of freedom ## Multiple R-squared: 0.4236, Adjusted R-squared: 0.3839 ## F-statistic: 10.66 on 2 and 29 DF, p-value: 0.0003391 Before correction, the batch effect is statistically significant (P \\(&lt;\\) 0.001), as indicated in the sponge.batch2 row. sponge.lm.bmc &lt;- lm(sponge.bmc[ ,9] ~ sponge.trt + sponge.batch) summary(sponge.lm.bmc) ## ## Call: ## lm(formula = sponge.bmc[, 9] ~ sponge.trt + sponge.batch) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.87967 -0.24705 0.04588 0.24492 1.00757 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -5.323e-02 1.497e-01 -0.356 0.725 ## sponge.trtE 1.065e-01 1.729e-01 0.616 0.543 ## sponge.batch2 -3.925e-17 1.729e-01 0.000 1.000 ## ## Residual standard error: 0.489 on 29 degrees of freedom ## Multiple R-squared: 0.01291, Adjusted R-squared: -0.05517 ## F-statistic: 0.1896 on 2 and 29 DF, p-value: 0.8283 After BMC correction, the batch effect is not statistically significant (P \\(&gt;\\) 0.05), as indicated in the sponge.batch2 row. The results from other batch correction methods are similar as BMC correction. sponge.lm.combat &lt;- lm(sponge.combat[ ,9] ~ sponge.trt + sponge.batch) summary(sponge.lm.combat) sponge.lm.limma &lt;- lm(sponge.limma[ ,9] ~ sponge.trt + sponge.batch) summary(sponge.lm.limma) sponge.lm.percentile &lt;- lm(sponge.percentile[ ,9] ~ sponge.trt + sponge.batch) summary(sponge.lm.percentile) sponge.lm.svd &lt;- lm(sponge.svd[ ,9] ~ sponge.trt + sponge.batch) summary(sponge.lm.svd) In sponge data, the results of density plots and P-values of batch effects from linear models reach a consesus with boxplots, the difference between two batches are removed by BMC, ComBat, removeBatchEffect and percentile normalisation correction. We observe that percentile normalisation modifies the distribution of the samples from the two batches. # ad data # boxplot ad.before.df &lt;- data.frame(value = ad.clr[ ,1], batch = ad.batch) ad.boxplot.before &lt;- box_plot_fun(data = ad.before.df, x = ad.before.df$batch, y = ad.before.df$value, title = &#39;OTU12 - before (AD)&#39;, batch.legend.title = &#39;Date (batch)&#39;, x.angle = 45, x.hjust = 1) ad.bmc.df &lt;- data.frame(value = ad.bmc[ ,1], batch = ad.batch) ad.boxplot.bmc &lt;- box_plot_fun(data = ad.bmc.df,x = ad.bmc.df$batch, y = ad.bmc.df$value, title = &#39;OTU12 - BMC (AD)&#39;, batch.legend.title = &#39;Date (batch)&#39;, x.angle = 45, x.hjust = 1) ad.combat.df &lt;- data.frame(value = ad.combat[ ,1], batch = ad.batch) ad.boxplot.combat &lt;- box_plot_fun(data = ad.combat.df, x = ad.combat.df$batch, y = ad.combat.df$value, title = &#39;OTU12 - ComBat (AD)&#39;, batch.legend.title = &#39;Date (batch)&#39;, x.angle = 45, x.hjust = 1) ad.limma.df &lt;- data.frame(value = ad.limma[ ,1], batch = ad.batch) ad.boxplot.limma &lt;- box_plot_fun(data = ad.limma.df,x = ad.limma.df$batch, y = ad.limma.df$value, title = &#39;OTU12 - rBE (AD)&#39;, batch.legend.title = &#39;Date (batch)&#39;, x.angle = 45, x.hjust = 1) ad.percentile.df &lt;- data.frame(value = ad.percentile[ ,1], batch = ad.batch) ad.boxplot.percentile &lt;- box_plot_fun(data = ad.percentile.df,x = ad.percentile.df$batch, y = ad.percentile.df$value, title = &#39;OTU12 - PN (AD)&#39;, batch.legend.title = &#39;Date (batch)&#39;, x.angle = 45, x.hjust = 1) ad.svd.df &lt;- data.frame(value = ad.svd[ ,1], batch = ad.batch) ad.boxplot.svd &lt;- box_plot_fun(data = ad.svd.df,x = ad.svd.df$batch, y = ad.svd.df$value, title = &#39;OTU12 - SVD (AD)&#39;, batch.legend.title = &#39;Date (batch)&#39;, x.angle = 45, x.hjust = 1) ad.ruv.df &lt;- data.frame(value = ad.ruvIII[ ,1], batch = ad.batch) ad.boxplot.ruv &lt;- box_plot_fun(data = ad.ruv.df,x = ad.ruv.df$batch, y = ad.ruv.df$value, title = &#39;OTU12 - RUVIII (AD)&#39;, batch.legend.title = &#39;Date (batch)&#39;, x.angle = 45, x.hjust = 1) grid.arrange(ad.boxplot.before, ad.boxplot.bmc, ad.boxplot.combat, ad.boxplot.limma, ncol = 2) grid.arrange(ad.boxplot.before, ad.boxplot.percentile, ad.boxplot.svd, ad.boxplot.ruv, ncol = 2) From the boxplots of OTU9 in AD data, the difference between five batches are removed by BMC, ComBat, removeBatchEffect and RUVIII correction. Among these methods, RUVIII did not remove as much batch difference as the other methods. # density plot # before ad.dens.before &lt;- ggplot(ad.before.df, aes(x = value, fill = batch)) + geom_density(alpha = 0.5) + scale_fill_manual(values = color.mixo(1:10)) + labs(title = &#39;OTU12 - before (AD)&#39;, x = &#39;Value&#39;, fill = &#39;Date (batch)&#39;) + theme_bw() + theme(plot.title = element_text(hjust = 0.5), panel.grid = element_blank()) # BMC ad.dens.bmc &lt;- ggplot(ad.bmc.df, aes(x = value, fill = batch)) + geom_density(alpha = 0.5) + scale_fill_manual(values = color.mixo(1:10)) + labs(title = &#39;OTU12 - BMC (AD)&#39;, x = &#39;Value&#39;, fill = &#39;Date (batch)&#39;) + theme_bw() + theme(plot.title = element_text(hjust = 0.5), panel.grid = element_blank()) # ComBat ad.dens.combat &lt;- ggplot(ad.combat.df, aes(x = value, fill = batch)) + geom_density(alpha = 0.5) + scale_fill_manual(values = color.mixo(1:10)) + labs(title = &#39;OTU12 - ComBat (AD)&#39;, x = &#39;Value&#39;, fill = &#39;Date (batch)&#39;) + theme_bw() + theme(plot.title = element_text(hjust = 0.5), panel.grid = element_blank()) # removeBatchEffect ad.dens.limma &lt;- ggplot(ad.limma.df, aes(x = value, fill = batch)) + geom_density(alpha = 0.5) + scale_fill_manual(values = color.mixo(1:10)) + labs(title = &#39;OTU12 - rBE (AD)&#39;, x = &#39;Value&#39;, fill = &#39;Date (batch)&#39;) + theme_bw() + theme(plot.title = element_text(hjust = 0.5), panel.grid = element_blank()) # percentile norm ad.dens.percentile &lt;- ggplot(ad.percentile.df, aes(x = value, fill = batch)) + geom_density(alpha = 0.5) + scale_fill_manual(values = color.mixo(1:10)) + labs(title = &#39;OTU12 - PN (AD)&#39;, x = &#39;Value&#39;, fill = &#39;Date (batch)&#39;) + theme_bw() + theme(plot.title = element_text(hjust = 0.5), panel.grid = element_blank()) # SVD ad.dens.svd &lt;- ggplot(ad.svd.df, aes(x = value, fill = batch)) + geom_density(alpha = 0.5) + scale_fill_manual(values = color.mixo(1:10)) + labs(title = &#39;OTU12 - SVD (AD)&#39;, x = &#39;Value&#39;, fill = &#39;Date (batch)&#39;) + theme_bw() + theme(plot.title = element_text(hjust = 0.5), panel.grid = element_blank()) # RUVIII ad.dens.ruv &lt;- ggplot(ad.ruv.df, aes(x = value, fill = batch)) + geom_density(alpha = 0.5) + scale_fill_manual(values = color.mixo(1:10)) + labs(title = &#39;OTU12 - RUVIII (AD)&#39;, x = &#39;Value&#39;, fill = &#39;Date (batch)&#39;) + theme_bw() + theme(plot.title = element_text(hjust = 0.5), panel.grid = element_blank()) grid.arrange(ad.dens.before, ad.dens.bmc, ad.dens.combat, ad.dens.limma, ncol = 2) grid.arrange(ad.dens.before, ad.dens.percentile, ad.dens.svd, ad.dens.ruv, ncol = 2) Similar as sponge data, we can also assess the batch effect in AD data using linear model. #p-values ad.lm.before &lt;- lm(ad.clr[ ,1] ~ ad.trt + ad.batch) anova(ad.lm.before) ## Analysis of Variance Table ## ## Response: ad.clr[, 1] ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## ad.trt 1 1.460 1.4605 3.1001 0.08272 . ## ad.batch 4 32.889 8.2222 17.4532 6.168e-10 *** ## Residuals 69 32.506 0.4711 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #summary(ad.lm.before) Before correction, the batch effect is statistically significant (P \\(&lt;\\) 0.001), as indicated in the ad.batch row. ad.lm.bmc &lt;- lm(ad.bmc[ ,1] ~ ad.trt + ad.batch) anova(ad.lm.bmc) ## Analysis of Variance Table ## ## Response: ad.bmc[, 1] ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## ad.trt 1 0.631 0.63084 1.3391 0.2512 ## ad.batch 4 0.036 0.00893 0.0190 0.9993 ## Residuals 69 32.506 0.47110 #summary(ad.lm.bmc) After BMC correction, the batch effect is not statistically significant (P \\(&gt;\\) 0.05), as indicated in the ad.batch row.The results from other batch correction methods are similar as BMC correction. ad.lm.combat &lt;- lm(ad.combat[ ,1] ~ ad.trt + ad.batch) anova(ad.lm.combat) #summary(ad.lm.combat) ad.lm.limma &lt;- lm(ad.limma[ ,1] ~ ad.trt + ad.batch) anova(ad.lm.limma) #summary(ad.lm.limma) ad.lm.percentile &lt;- lm(ad.percentile[ ,1] ~ ad.trt + ad.batch) anova(ad.lm.percentile) #summary(ad.lm.percentile) ad.lm.svd &lt;- lm(ad.svd[ ,1] ~ ad.trt + ad.batch) anova(ad.lm.svd) #summary(ad.lm.svd) ad.lm.ruv &lt;- lm(ad.ruvIII[ ,1] ~ ad.trt + ad.batch) anova(ad.lm.ruv) #summary(ad.lm.ruv) The results of density plots and P-values of batch effects from linear models reach a consesus with boxplots, the difference between two batches are removed by BMC, ComBat, removeBatchEffect and RUVIII correction. 4.1.3 RLE plots In sponge data, we group the samples according to the tissue (choanosome / ectosome) and generate two RLE plots respectively in all datasets before and after batch correction with different methods: # sponge data # BMC sponge.bmc_c &lt;- sponge.bmc[sponge.trt == &#39;C&#39;, ] sponge.bmc_e &lt;- sponge.bmc[sponge.trt == &#39;E&#39;, ] # ComBat sponge.combat_c &lt;- sponge.combat[sponge.trt == &#39;C&#39;, ] sponge.combat_e &lt;- sponge.combat[sponge.trt == &#39;E&#39;, ] # rBE sponge.limma_c &lt;- sponge.limma[sponge.trt == &#39;C&#39;, ] sponge.limma_e &lt;- sponge.limma[sponge.trt == &#39;E&#39;, ] # PN sponge.percentile_c &lt;- sponge.percentile[sponge.trt == &#39;C&#39;, ] sponge.percentile_e &lt;- sponge.percentile[sponge.trt == &#39;E&#39;, ] # SVD sponge.svd_c &lt;- sponge.svd[sponge.trt == &#39;C&#39;, ] sponge.svd_e &lt;- sponge.svd[sponge.trt == &#39;E&#39;, ] par(mfrow = c(2,3), mai = c(0.4,0.6,0.3,0.1)) RleMicroRna2(object = t(sponge.before_c), batch = sponge.batch_c, maintitle = &#39;Sponge: before (choanosome)&#39;, title.cex = 1) RleMicroRna2(object = t(sponge.bmc_c), batch = sponge.batch_c, maintitle = &#39;Sponge: BMC (choanosome)&#39;, title.cex = 1) RleMicroRna2(object = t(sponge.combat_c), batch = sponge.batch_c, maintitle = &#39;Sponge: ComBat (choanosome)&#39;, title.cex = 1) RleMicroRna2(object = t(sponge.limma_c), batch = sponge.batch_c, maintitle = &#39;Sponge: rBE (choanosome)&#39;, title.cex = 1) RleMicroRna2(object = t(sponge.percentile_c), batch = sponge.batch_c, maintitle = &#39;Sponge: PN (choanosome)&#39;, title.cex = 1) RleMicroRna2(object = t(sponge.svd_c), batch = sponge.batch_c, maintitle = &#39;Sponge: SVD (choanosome)&#39;, title.cex = 1) par(mfrow = c(1,1)) In tissue choanosome of sponge data, the batch effect before correction is not obvious as all medians of samples are close to zero, but Gel2 has a greater interquartile range (IQR) than the other samples. Percentile normalisation increased batch effects, as the samples after correction are deviated from zero and the IQR is increased. Among other methods, the IQR of all the box plots (samples) from different batches is consistent after ComBat correction. par(mfrow = c(2,3), mai = c(0.4,0.6,0.3,0.1)) RleMicroRna2(object = t(sponge.before_e), batch = sponge.batch_e, maintitle = &#39;Sponge: before (ectosome)&#39;, title.cex = 1) RleMicroRna2(object = t(sponge.bmc_e), batch = sponge.batch_e, maintitle = &#39;Sponge: BMC (ectosome)&#39;, title.cex = 1) RleMicroRna2(object = t(sponge.combat_e), batch = sponge.batch_e, maintitle = &#39;Sponge: ComBat (ectosome)&#39;, title.cex = 1) RleMicroRna2(object = t(sponge.limma_e), batch = sponge.batch_e, maintitle = &#39;Sponge: rBE (ectosome)&#39;, title.cex = 1) RleMicroRna2(object = t(sponge.percentile_e), batch = sponge.batch_e, maintitle = &#39;Sponge: PN (ectosome)&#39;, title.cex = 1) RleMicroRna2(object = t(sponge.svd_e), batch = sponge.batch_e, maintitle = &#39;Sponge: SVD (ectosome)&#39;, title.cex = 1) par(mfrow = c(1,1)) In tissue ectosome of sponge data, batch effect is not easily detected, but percentile normalisation increased batch variation. In AD data, we group the samples according to the inital phenol concentration (0-0.5 g/L / 1-2 g/L) and generate two RLE plots respectively in all datasets before and after batch correction, as sponge data: # ad data # BMC ad.bmc_05 &lt;- ad.bmc[ad.trt == &#39;0-0.5&#39;, ] ad.bmc_2 &lt;- ad.bmc[ad.trt == &#39;1-2&#39;, ] # ComBat ad.combat_05 &lt;- ad.combat[ad.trt == &#39;0-0.5&#39;, ] ad.combat_2 &lt;- ad.combat[ad.trt == &#39;1-2&#39;, ] # rBE ad.limma_05 &lt;- ad.limma[ad.trt == &#39;0-0.5&#39;, ] ad.limma_2 &lt;- ad.limma[ad.trt == &#39;1-2&#39;, ] # PN ad.percentile_05 &lt;- ad.percentile[ad.trt == &#39;0-0.5&#39;, ] ad.percentile_2 &lt;- ad.percentile[ad.trt == &#39;1-2&#39;, ] # SVD ad.svd_05 &lt;- ad.svd[ad.trt == &#39;0-0.5&#39;, ] ad.svd_2 &lt;- ad.svd[ad.trt == &#39;1-2&#39;, ] # RUVIII ad.ruv_05 &lt;- ad.ruvIII[ad.trt == &#39;0-0.5&#39;, ] ad.ruv_2 &lt;- ad.ruvIII[ad.trt == &#39;1-2&#39;, ] par(mfrow = c(2,2), mai = c(0.5,0.8,0.3,0.1)) RleMicroRna2(object = t(ad.before_05), batch = ad.batch_05, maintitle = &#39;AD: before (0-0.5 g/L)&#39;, legend.cex = 0.4, cex.xaxis = 0.5) RleMicroRna2(object = t(ad.bmc_05), batch = ad.batch_05, maintitle = &#39;AD: BMC (0-0.5 g/L)&#39;, legend.cex = 0.4, cex.xaxis = 0.5) RleMicroRna2(object = t(ad.combat_05), batch = ad.batch_05, maintitle = &#39;AD: ComBat (0-0.5 g/L)&#39;, legend.cex = 0.4, cex.xaxis = 0.5) RleMicroRna2(object = t(ad.limma_05), batch = ad.batch_05, maintitle = &#39;AD: rBE (0-0.5 g/L)&#39;, legend.cex = 0.4, cex.xaxis = 0.5) RleMicroRna2(object = t(ad.percentile_05), batch = ad.batch_05, maintitle = &#39;AD: PN (0-0.5 g/L)&#39;, legend.cex = 0.4, cex.xaxis = 0.5) RleMicroRna2(object = t(ad.svd_05), batch = ad.batch_05, maintitle = &#39;AD: SVD (0-0.5 g/L)&#39;, legend.cex = 0.4, cex.xaxis = 0.5) RleMicroRna2(object = t(ad.ruv_05), batch = ad.batch_05, maintitle = &#39;AD: RUVIII (0-0.5 g/L)&#39;, legend.cex = 0.4, cex.xaxis = 0.5) par(mfrow = c(1,1)) In AD data with initial phenol concentration between 0-0.5 g/L, batch effect is not easily detected, but percentile normalisation increased batch variation. par(mfrow = c(2,2), mai = c(0.35,0.8,0.3,0.1)) RleMicroRna2(object = t(ad.before_2), batch = ad.batch_2, maintitle = &#39;AD: before (1-2 g/L)&#39;, legend.cex = 0.4, cex.xaxis = 0.3) RleMicroRna2(object = t(ad.bmc_2), batch = ad.batch_2, maintitle = &#39;AD: BMC (1-2 g/L)&#39;, legend.cex = 0.4, cex.xaxis = 0.3) RleMicroRna2(object = t(ad.combat_2), batch = ad.batch_2, maintitle = &#39;AD: ComBat (1-2 g/L)&#39;, legend.cex = 0.4, cex.xaxis = 0.3) RleMicroRna2(object = t(ad.limma_2), batch = ad.batch_2, maintitle = &#39;AD: rBE (1-2 g/L)&#39;, legend.cex = 0.4, cex.xaxis = 0.3) RleMicroRna2(object = t(ad.percentile_2), batch = ad.batch_2, maintitle = &#39;AD: PN (1-2 g/L)&#39;, legend.cex = 0.4, cex.xaxis = 0.3) RleMicroRna2(object = t(ad.svd_2), batch = ad.batch_2, maintitle = &#39;AD: SVD (1-2 g/L)&#39;, legend.cex = 0.4, cex.xaxis = 0.3) RleMicroRna2(object = t(ad.ruv_2), batch = ad.batch_2, maintitle = &#39;AD: RUVIII (1-2 g/L)&#39;, legend.cex = 0.4, cex.xaxis = 0.3) par(mfrow = c(1,1)) In AD data with initial phenol concentration between 1-2 g/L, batch effect is not easily detected, but percentile normalisation increased batch variation. 4.1.4 Heatmap We use the heatmap to visualise data clusters. Samples clustered by batches instead of treatments indicate a batch effect. # Sponge data # before sponge.tss.clr.scale &lt;- scale(sponge.tss.clr, center = T, scale = T) # scale on OTUs sponge.tss.clr.scale &lt;- scale(t(sponge.tss.clr.scale), center = T, scale = T) # scale on samples sponge.anno_col &lt;- data.frame(Batch = sponge.batch, Tissue = sponge.trt) sponge.anno_metabo_colors &lt;- list(Batch = c(&#39;1&#39; = &#39;#388ECC&#39;, &#39;2&#39; = &#39;#F68B33&#39;), Tissue = c(C = &#39;#F0E442&#39;, E = &#39;#D55E00&#39;)) pheatmap(sponge.tss.clr.scale, scale = &#39;none&#39;, cluster_rows = F, cluster_cols = T, fontsize_row = 5, fontsize_col = 8, fontsize = 8, clustering_distance_rows = &#39;euclidean&#39;, clustering_method = &#39;ward.D&#39;, treeheight_row = 30, annotation_col = sponge.anno_col, annotation_colors = sponge.anno_metabo_colors, border_color = &#39;NA&#39;, main = &#39;Sponge data - before&#39;) Before correction, samples in sponge data are preferentially clustered by batch instead of tissue type, indicating a batch effect. # ComBat sponge.combat.scale &lt;- scale(sponge.combat, center = T, scale = T) # scale on OTUs sponge.combat.scale &lt;- scale(t(sponge.combat.scale), center = T, scale = T) # scale on samples pheatmap(sponge.combat.scale, scale = &#39;none&#39;, cluster_rows = F, cluster_cols = T, fontsize_row = 5, fontsize_col = 8, fontsize = 8, clustering_distance_rows = &#39;euclidean&#39;, clustering_method = &#39;ward.D&#39;, treeheight_row = 30, annotation_col = sponge.anno_col, annotation_colors = sponge.anno_metabo_colors, border_color = &#39;NA&#39;, main = &#39;Sponge data - ComBat&#39;) After batch correction with ComBat, the data are clustered by tissues rather than batches, therefore, ComBat not only removed batch effects, but also disengaged the effect of interest. The results from batch correction with other methods are similar. # BMC sponge.bmc.scale &lt;- scale(sponge.bmc, center = T, scale = T) # scale on OTUs sponge.bmc.scale &lt;- scale(t(sponge.bmc.scale), center = T, scale = T) # scale on samples pheatmap(sponge.bmc.scale, scale = &#39;none&#39;, cluster_rows = F, cluster_cols = T, fontsize_row = 5, fontsize_col = 8, fontsize = 8, clustering_distance_rows = &#39;euclidean&#39;, clustering_method = &#39;ward.D&#39;, treeheight_row = 30, annotation_col = sponge.anno_col, annotation_colors = sponge.anno_metabo_colors, border_color = &#39;NA&#39;, main = &#39;Sponge data - BMC&#39;) # removeBatchEffect sponge.limma.scale &lt;- scale(sponge.limma, center = T, scale = T) # scale on OTUs sponge.limma.scale &lt;- scale(t(sponge.limma.scale), center = T, scale = T) # scale on samples pheatmap(sponge.limma.scale, scale = &#39;none&#39;, cluster_rows = F, cluster_cols = T, fontsize_row = 5, fontsize_col = 8, fontsize = 8, clustering_distance_rows = &#39;euclidean&#39;, clustering_method = &#39;ward.D&#39;, treeheight_row = 30, annotation_col = sponge.anno_col, annotation_colors = sponge.anno_metabo_colors, border_color = &#39;NA&#39;, main = &#39;Sponge data - removeBatchEffect&#39;) # percentile normalisation sponge.percentile.scale &lt;- scale(sponge.percentile, center = T, scale = T) # scale on OTUs sponge.percentile.scale &lt;- scale(t(sponge.percentile.scale), center = T, scale = T) # scale on samples pheatmap(sponge.percentile.scale, scale = &#39;none&#39;, cluster_rows = F, cluster_cols = T, fontsize_row = 5, fontsize_col = 8, fontsize = 8, clustering_distance_rows = &#39;euclidean&#39;, clustering_method = &#39;ward.D&#39;, treeheight_row = 30, annotation_col = sponge.anno_col, annotation_colors = sponge.anno_metabo_colors, border_color = &#39;NA&#39;, main = &#39;Sponge data - percentile norm&#39;) # SVD sponge.svd.scale &lt;- scale(sponge.svd, center = T, scale = T) # scale on OTUs sponge.svd.scale &lt;- scale(t(sponge.svd.scale), center = T, scale = T) # scale on samples pheatmap(sponge.svd.scale, scale = &#39;none&#39;, cluster_rows = F, cluster_cols = T, fontsize_row = 5, fontsize_col = 8, fontsize = 8, clustering_distance_rows = &#39;euclidean&#39;, clustering_method = &#39;ward.D&#39;, treeheight_row = 30, annotation_col = sponge.anno_col, annotation_colors = sponge.anno_metabo_colors, border_color = &#39;NA&#39;, main = &#39;Sponge data - SVD&#39;) In the heatmap of AD data before batch correction, samples within batch 14/04/2016 are clustered and distinct from other samples, indicating a batch effect. # AD data # before ad.clr.scale &lt;- scale(ad.clr, center = T, scale = T) # scale on OTUs ad.clr.scale &lt;- scale(t(ad.clr.scale), center = T, scale = T) # scale on samples ad.anno_col &lt;- data.frame(Batch = ad.batch, Treatment = ad.trt) ad.anno_metabo_colors &lt;- list(Batch = c(&#39;09/04/2015&#39; = &#39;#388ECC&#39;, &#39;14/04/2016&#39; = &#39;#F68B33&#39;, &#39;01/07/2016&#39; = &#39;#C2C2C2&#39;, &#39;14/11/2016&#39; = &#39;#009E73&#39;, &#39;21/09/2017&#39; = &#39;#CC79A7&#39;), Treatment = c(&#39;0-0.5&#39; = &#39;#0072B2&#39;, &#39;1-2&#39; = &#39;#999999&#39;)) pheatmap(ad.clr.scale, scale = &#39;none&#39;, cluster_rows = F, cluster_cols = T, fontsize_row = 4, fontsize_col = 6, fontsize = 8, clustering_distance_rows = &#39;euclidean&#39;, clustering_method = &#39;ward.D&#39;, treeheight_row = 30, annotation_col = ad.anno_col, annotation_colors = ad.anno_metabo_colors, border_color = &#39;NA&#39;, main = &#39;AD data - before&#39;) # removeBatchEffect ad.limma.scale &lt;- scale(ad.limma, center = T, scale = T) # scale on OTUs ad.limma.scale &lt;- scale(t(ad.limma.scale), center = T, scale = T) # scale on samples pheatmap(ad.limma.scale, scale = &#39;none&#39;, cluster_rows = F, cluster_cols = T, fontsize_row = 4, fontsize_col = 6, fontsize = 8, clustering_distance_rows = &#39;euclidean&#39;, clustering_method = &#39;ward.D&#39;, treeheight_row = 30, annotation_col = ad.anno_col, annotation_colors = ad.anno_metabo_colors, border_color = &#39;NA&#39;, main = &#39;AD data - removeBatchEffect&#39;) After batch correction with removeBatchEffect, the data are almost clustered by treatments rather than batches, therefore, removeBatchEffect not only removed batch effects, but also disengaged the treatment effects. The results from batch correction with other methods are similar. # BMC ad.bmc.scale &lt;- scale(ad.bmc, center = T, scale = T) # scale on OTUs ad.bmc.scale &lt;- scale(t(ad.bmc.scale), center = T, scale = T) # scale on samples pheatmap(ad.bmc.scale, scale = &#39;none&#39;, cluster_rows = F, cluster_cols = T, fontsize_row = 4, fontsize_col = 6, fontsize = 8, clustering_distance_rows = &#39;euclidean&#39;, clustering_method = &#39;ward.D&#39;, treeheight_row = 30, annotation_col = ad.anno_col, annotation_colors = ad.anno_metabo_colors, border_color = &#39;NA&#39;, main = &#39;AD data - BMC&#39;) # ComBat ad.combat.scale &lt;- scale(ad.combat, center = T, scale = T) # scale on OTUs ad.combat.scale &lt;- scale(t(ad.combat.scale), center = T, scale = T) # scale on samples pheatmap(ad.combat.scale, scale = &#39;none&#39;, cluster_rows = F, cluster_cols = T, fontsize_row = 4, fontsize_col = 6, fontsize = 8, clustering_distance_rows = &#39;euclidean&#39;, clustering_method = &#39;ward.D&#39;, treeheight_row = 30, annotation_col = ad.anno_col, annotation_colors = ad.anno_metabo_colors, border_color = &#39;NA&#39;, main = &#39;AD data - ComBat&#39;) # percentile normalisation ad.percentile.scale &lt;- scale(ad.percentile, center = T, scale = T) # scale on OTUs ad.percentile.scale &lt;- scale(t(ad.percentile.scale), center = T, scale = T) # scale on samples pheatmap(ad.percentile.scale, scale = &#39;none&#39;, cluster_rows = F, cluster_cols = T, fontsize_row = 4, fontsize_col = 6, fontsize = 8, clustering_distance_rows = &#39;euclidean&#39;, clustering_method = &#39;ward.D&#39;, treeheight_row = 30, annotation_col = ad.anno_col, annotation_colors = ad.anno_metabo_colors, border_color = &#39;NA&#39;, main = &#39;AD data - percentile norm&#39;) # SVD ad.svd.scale &lt;- scale(ad.svd, center = T, scale = T) # scale on OTUs ad.svd.scale &lt;- scale(t(ad.svd.scale), center = T, scale = T) # scale on samples pheatmap(ad.svd.scale, scale = &#39;none&#39;, cluster_rows = F, cluster_cols = T, fontsize_row = 4, fontsize_col = 6, fontsize = 8, clustering_distance_rows = &#39;euclidean&#39;, clustering_method = &#39;ward.D&#39;, treeheight_row = 30, annotation_col = ad.anno_col, annotation_colors = ad.anno_metabo_colors, border_color = &#39;NA&#39;, main = &#39;AD data - SVD&#39;) # RUVIII ad.ruv.scale &lt;- scale(ad.ruvIII, center = T, scale = T) # scale on OTUs ad.ruv.scale &lt;- scale(t(ad.ruv.scale), center = T, scale = T) # scale on samples pheatmap(ad.ruv.scale, scale = &#39;none&#39;, cluster_rows = F, cluster_cols = T, fontsize_row = 4, fontsize_col = 6, fontsize = 8, clustering_distance_rows = &#39;euclidean&#39;, clustering_method = &#39;ward.D&#39;, treeheight_row = 30, annotation_col = ad.anno_col, annotation_colors = ad.anno_metabo_colors, border_color = &#39;NA&#39;, main = &#39;AD data - RUVIII&#39;) 4.2 Variance calculation Compared to diagnostic plots, quantitative approaches are more objective and direct. The evaluation is done quantitatively before and after batch effect removal and the biological (treatment) effect must also be assessed before and after the batch effect correction to ensure it has been preserved. 4.2.1 Linear model per variable The variance explained by batch or treatment per OTU can be calculated by a linear model. Box plots can then be used to visualise the variance calculated from each OTU. Following batch effect correction, the percentage of variance explained by the treatment should be greater than the batch. We use a function fitExtractVarPartModel to calculate and extract the variance of batch and treatment per OTU. # Sponge data sponge.form &lt;- ~ sponge.trt + sponge.batch sponge.info &lt;- as.data.frame(cbind(rownames(sponge.tss.clr), sponge.trt, sponge.batch)) rownames(sponge.info) &lt;- rownames(sponge.tss.clr) # before sponge.varPart.before &lt;- fitExtractVarPartModel(exprObj = t(sponge.tss.clr), formula = sponge.form, data = sponge.info) # BMC sponge.varPart.bmc &lt;- fitExtractVarPartModel(exprObj = t(sponge.bmc), formula = sponge.form, data = sponge.info) # combat sponge.varPart.combat &lt;- fitExtractVarPartModel(exprObj = t(sponge.combat), formula = sponge.form, data = sponge.info) # removeBatchEffect sponge.varPart.limma &lt;- fitExtractVarPartModel(exprObj = t(sponge.limma), formula = sponge.form, data = sponge.info) # percentile normalisation sponge.varPart.percentile &lt;- fitExtractVarPartModel(exprObj = t(sponge.percentile), formula = sponge.form, data = sponge.info) # svd sponge.varPart.svd &lt;- fitExtractVarPartModel(exprObj = t(sponge.svd), formula = sponge.form, data = sponge.info) # extract the variance of trt and batch # before sponge.varmat.before &lt;- as.matrix(sponge.varPart.before[ ,1:2]) # BMC sponge.varmat.bmc &lt;- as.matrix(sponge.varPart.bmc[ ,1:2]) # ComBat sponge.varmat.combat &lt;- as.matrix(sponge.varPart.combat[ ,1:2]) # removeBatchEffect sponge.varmat.limma &lt;- as.matrix(sponge.varPart.limma[ ,1:2]) # percentile normalisation sponge.varmat.percentile &lt;- as.matrix(sponge.varPart.percentile[ ,1:2]) # SVD sponge.varmat.svd &lt;- as.matrix(sponge.varPart.svd[ ,1:2]) # merge results sponge.variance &lt;- c(as.vector(sponge.varmat.before), as.vector(sponge.varmat.bmc), as.vector(sponge.varmat.combat), as.vector(sponge.varmat.limma), as.vector(sponge.varmat.percentile), as.vector(sponge.varmat.svd)) # add batch, trt and methods info sponge.variance &lt;- cbind(variance = sponge.variance, Type = rep(c(&#39;Tissue&#39;, &#39;Batch&#39;), each = ncol(sponge.tss.clr)), method = rep(c(&#39;Before&#39;, &#39;BMC&#39;, &#39;ComBat&#39;, &#39;rBE&#39;, &#39;PN&#39;, &#39;SVD&#39;), each = 2*ncol(sponge.tss.clr))) # reorder levels sponge.variance &lt;- as.data.frame(sponge.variance) sponge.variance$method &lt;- factor(sponge.variance$method, levels = unique(sponge.variance$method)) sponge.variance$variance &lt;- as.numeric(as.character(sponge.variance$variance)) ggplot(sponge.variance, aes(x = Type, y = variance, fill = Type)) + geom_boxplot() + facet_grid(cols = vars(method)) + theme_bw() + theme(axis.text.x = element_text(angle = 60, hjust = 1), strip.text = element_text(size = 12), panel.grid = element_blank(), axis.text = element_text(size = 12), axis.title = element_text(size = 15), legend.title = element_text(size = 15), legend.text = element_text(size = 12)) + labs(x = &#39;Type&#39;, y = &#39;Proportion Variance&#39;, name = &#39;Type&#39;) + ylim(0,1) BMC, ComBat and removeBatchEffect successfully removed batch variation while preserving treatment variation, but SVD performed poorly. Percentile normalisation preserved sufficient treatment variation, but removed less batch effect variation than BMC, ComBat and removeBatchEffect. Percentile normalisation used percentiles instead of actual values. This leads to information loss. Moreover, it was designed for case-control microbiome studies, which differ from our example studies. This method would therefore be more effective with control samples in each batch. SVD was inefficient at targeting batch effects, as it assumes that batch effects cause the largest variation in the data and should therefore appear as the first component. However, in sponge data the batch effect is mainly present on the second component as was shown in PCA sample plots with density, which results in a miscorrection of batch effects. We also calculate the variance for AD data. # AD data ad.form &lt;- ~ ad.trt + ad.batch ad.info &lt;- as.data.frame(cbind(rownames(ad.clr), ad.trt,ad.batch)) rownames(ad.info) &lt;- rownames(ad.clr) # before ad.varPart.before &lt;- fitExtractVarPartModel(exprObj = t(ad.clr), formula = ad.form, data = ad.info) # BMC ad.varPart.bmc &lt;- fitExtractVarPartModel(exprObj = t(ad.bmc), formula = ad.form, data = ad.info) # combat ad.varPart.combat &lt;- fitExtractVarPartModel(exprObj = t(ad.combat), formula = ad.form, data = ad.info) # removeBatchEffect ad.varPart.limma &lt;- fitExtractVarPartModel(exprObj = t(ad.limma), formula = ad.form, data = ad.info) # percentile normalisation ad.varPart.percentile &lt;- fitExtractVarPartModel(exprObj = t(ad.percentile), formula = ad.form, data = ad.info) # svd ad.varPart.svd &lt;- fitExtractVarPartModel(exprObj = t(ad.svd), formula = ad.form, data = ad.info) # ruv ad.varPart.ruv &lt;- fitExtractVarPartModel(exprObj = t(ad.ruvIII), formula = ad.form, data = ad.info) # extract the variance of trt and batch # before ad.varmat.before &lt;- as.matrix(ad.varPart.before[ ,1:2]) # BMC ad.varmat.bmc &lt;- as.matrix(ad.varPart.bmc[ ,1:2]) # ComBat ad.varmat.combat &lt;- as.matrix(ad.varPart.combat[ ,1:2]) # removeBatchEffect ad.varmat.limma &lt;- as.matrix(ad.varPart.limma[ ,1:2]) # percentile normalisation ad.varmat.percentile &lt;- as.matrix(ad.varPart.percentile[ ,1:2]) # SVD ad.varmat.svd &lt;- as.matrix(ad.varPart.svd[ ,1:2]) # RUVIII ad.varmat.ruv &lt;- as.matrix(ad.varPart.ruv[ ,1:2]) # merge results ad.variance &lt;- c(as.vector(ad.varmat.before), as.vector(ad.varmat.bmc), as.vector(ad.varmat.combat), as.vector(ad.varmat.limma), as.vector(ad.varmat.percentile), as.vector(ad.varmat.svd), as.vector(ad.varmat.ruv)) # add batch, trt and methods info ad.variance &lt;- cbind(variance = ad.variance, Type = rep(c( &#39;Treatment&#39;, &#39;Batch&#39;), each = ncol(ad.clr)), method = rep(c(&#39;Before&#39;, &#39;BMC&#39;, &#39;ComBat&#39;, &#39;rBE&#39;, &#39;PN&#39;, &#39;SVD&#39;, &#39;RUVIII&#39;), each = 2*ncol(ad.clr))) # reorder levels ad.variance &lt;- as.data.frame(ad.variance) ad.variance$method &lt;- factor(ad.variance$method, levels = unique(ad.variance$method)) ad.variance$variance &lt;- as.numeric(as.character(ad.variance$variance)) ggplot(ad.variance, aes(x = Type, y = variance, fill = Type)) + geom_boxplot() + facet_grid(cols = vars(method)) + theme_bw() + theme(axis.text.x = element_text(angle = 60, hjust = 1), strip.text = element_text(size = 11), panel.grid = element_blank(), axis.text = element_text(size = 12), axis.title = element_text(size = 15), legend.title = element_text(size = 15), legend.text = element_text(size = 12)) + labs(x = &quot;Type&quot;, y = &quot;Proportion Variance&quot;, name = &#39;Type&#39;) + scale_fill_hue(l = 40) + ylim(0,1) Similar results as in sponge data, BMC, ComBat and removeBatchEffect successfully removed batch variation while preserving treatment variation, but SVD performed poorly. Percentile normalisation and RUVIII preserved sufficient treatment variation, but removed less batch effect variation than BMC, ComBat and removeBatchEffect. It is possible the negative control variables or technical replicate samples did not entirely capture the batch effects. SVD was also inefficient at targeting batch effects, as in AD data the batch effect is present on both first and second components, which results in a miscorrection of batch effects. 4.2.2 RDA The pRDA method is a multivariate method to assess globally the effect of batch and treatment (two separate models). # Sponge data sponge.data.design &lt;- numeric() sponge.data.design$group &lt;- sponge.trt sponge.data.design$batch &lt;- sponge.batch # before # conditioning on a batch effect sponge.rda.before1 &lt;- rda(sponge.tss.clr ~ group + Condition(batch), data = sponge.data.design) sponge.rda.before2 &lt;- rda(sponge.tss.clr ~ batch + Condition(group), data = sponge.data.design) # amount of variance sponge.rda.bat_prop.before &lt;- sponge.rda.before1$pCCA$tot.chi*100/sponge.rda.before1$tot.chi sponge.rda.trt_prop.before &lt;- sponge.rda.before2$pCCA$tot.chi*100/sponge.rda.before2$tot.chi # BMC # conditioning on a batch effect sponge.rda.bmc1 &lt;- rda(sponge.bmc ~ group + Condition(batch), data = sponge.data.design) sponge.rda.bmc2 &lt;- rda(sponge.bmc ~ batch + Condition(group), data = sponge.data.design) # amount of variance sponge.rda.bat_prop.bmc &lt;- sponge.rda.bmc1$pCCA$tot.chi*100/sponge.rda.bmc1$tot.chi sponge.rda.trt_prop.bmc &lt;- sponge.rda.bmc2$pCCA$tot.chi*100/sponge.rda.bmc2$tot.chi # combat # conditioning on a batch effect sponge.rda.combat1 &lt;- rda(sponge.combat ~ group + Condition(batch), data = sponge.data.design) sponge.rda.combat2 &lt;- rda(sponge.combat ~ batch + Condition(group), data = sponge.data.design) # amount of variance sponge.rda.bat_prop.combat &lt;- sponge.rda.combat1$pCCA$tot.chi*100/sponge.rda.combat1$tot.chi sponge.rda.trt_prop.combat &lt;- sponge.rda.combat2$pCCA$tot.chi*100/sponge.rda.combat2$tot.chi # limma # conditioning on a batch effect sponge.rda.limma1 &lt;- rda(sponge.limma ~ group + Condition(batch), data = sponge.data.design) sponge.rda.limma2 &lt;- rda(sponge.limma ~ batch + Condition(group), data = sponge.data.design) # amount of variance sponge.rda.bat_prop.limma &lt;- sponge.rda.limma1$pCCA$tot.chi*100/sponge.rda.limma1$tot.chi sponge.rda.trt_prop.limma &lt;- sponge.rda.limma2$pCCA$tot.chi*100/sponge.rda.limma2$tot.chi # percentile # conditioning on a batch effect sponge.rda.percentile1 &lt;- rda(sponge.percentile ~ group + Condition(batch), data = sponge.data.design) sponge.rda.percentile2 &lt;- rda(sponge.percentile ~ batch + Condition(group), data = sponge.data.design) # amount of variance sponge.rda.bat_prop.percentile &lt;- sponge.rda.percentile1$pCCA$tot.chi*100/sponge.rda.percentile1$tot.chi sponge.rda.trt_prop.percentile &lt;- sponge.rda.percentile2$pCCA$tot.chi*100/sponge.rda.percentile2$tot.chi # SVD # conditioning on a batch effect sponge.rda.svd1 &lt;- rda(sponge.svd ~ group + Condition(batch), data = sponge.data.design) sponge.rda.svd2 &lt;- rda(sponge.svd ~ batch + Condition(group), data = sponge.data.design) # amount of variance sponge.rda.bat_prop.svd &lt;- sponge.rda.svd1$pCCA$tot.chi*100/sponge.rda.svd1$tot.chi sponge.rda.trt_prop.svd &lt;- sponge.rda.svd2$pCCA$tot.chi*100/sponge.rda.svd2$tot.chi We now represent the amount of variance explained by batch and treatment estimated with pRDA: # proportion sponge.rda.prop.before &lt;- c(sponge.rda.bat_prop.before, sponge.rda.trt_prop.before) sponge.rda.prop.bmc &lt;- c(sponge.rda.bat_prop.bmc, sponge.rda.trt_prop.bmc) sponge.rda.prop.combat &lt;- c(sponge.rda.bat_prop.combat, sponge.rda.trt_prop.combat) sponge.rda.prop.limma &lt;- c(sponge.rda.bat_prop.limma, sponge.rda.trt_prop.limma) sponge.rda.prop.percentile &lt;- c(sponge.rda.bat_prop.percentile, sponge.rda.trt_prop.percentile) sponge.rda.prop.svd &lt;- c(sponge.rda.bat_prop.svd, sponge.rda.trt_prop.svd) # merge results sponge.rda.prop.val &lt;- c(sponge.rda.prop.before, sponge.rda.prop.bmc, sponge.rda.prop.combat, sponge.rda.prop.limma, sponge.rda.prop.percentile, sponge.rda.prop.svd) # add batch, trt and method info sponge.rda.prop &lt;- data.frame(prop = sponge.rda.prop.val, prop.r = round(sponge.rda.prop.val, 2), Method = rep(c(&#39;Before&#39;, &#39;BMC&#39;, &#39;ComBat&#39;, &#39;rBE&#39;, &#39;PN&#39;, &#39;SVD&#39;), each = 2), Type = rep(c(&#39;Batch&#39;, &#39;Tissue&#39;), 6)) # reorder levels sponge.rda.prop$Method &lt;- factor(sponge.rda.prop$Method, levels = unique(sponge.rda.prop$Method)) ggplot(data = sponge.rda.prop, aes(x = Method, y = prop, fill = Type)) + geom_bar(stat = &quot;identity&quot;, position = &#39;dodge&#39;, colour = &#39;black&#39;) + geom_text(data = sponge.rda.prop, aes(Method, prop + 2.5, label = prop.r), position = position_dodge(width = 0.9), size = 3) + theme_bw() + labs(y = &quot;Variance explained (%)&quot;) + theme(axis.text.x = element_text(angle = 60, hjust = 1), panel.grid = element_blank(), axis.text = element_text(size = 12), axis.title = element_text(size = 15), legend.title = element_text(size = 15), legend.text = element_text(size = 12)) + ylim(0,100) In sponge data, pRDA shows that BMC, ComBat and removeBatchEffect were more efficient at removing batch variation while preserving treatment variation. This result is in agreement with the proportional variance calculated using a linear model in the previous section ‘linear model per variable’. ComBat removed relatively less batch variation compared with the other two methods, which implies that the batch effect is not purely systematic. The low efficiency of percentile normalisation is more obvious in the variance calculated with pRDA. It did not remove enough batch variation, nor preserve enough treatment variation in sponge data. We also apply pRDA on AD data. # AD data ad.data.design &lt;- numeric() ad.data.design$group &lt;- ad.trt ad.data.design$batch &lt;- ad.batch # before # conditioning on a batch effect ad.rda.before1 &lt;- rda(ad.clr ~ group + Condition(batch), data = ad.data.design) ad.rda.before2 &lt;- rda(ad.clr ~ batch + Condition(group), data = ad.data.design) # amount of variance ad.rda.bat_prop.before &lt;- ad.rda.before1$pCCA$tot.chi*100/ad.rda.before1$tot.chi ad.rda.trt_prop.before &lt;- ad.rda.before2$pCCA$tot.chi*100/ad.rda.before2$tot.chi # BMC # conditioning on a batch effect ad.rda.bmc1 &lt;- rda(ad.bmc ~ group + Condition(batch), data = ad.data.design) ad.rda.bmc2 &lt;- rda(ad.bmc ~ batch + Condition(group), data = ad.data.design) # amount of variance ad.rda.bat_prop.bmc &lt;- ad.rda.bmc1$pCCA$tot.chi*100/ad.rda.bmc1$tot.chi ad.rda.trt_prop.bmc &lt;- ad.rda.bmc2$pCCA$tot.chi*100/ad.rda.bmc2$tot.chi # combat # conditioning on a batch effect ad.rda.combat1 &lt;- rda(ad.combat ~ group + Condition(batch), data = ad.data.design) ad.rda.combat2 &lt;- rda(ad.combat ~ batch + Condition(group), data = ad.data.design) # amount of variance ad.rda.bat_prop.combat &lt;- ad.rda.combat1$pCCA$tot.chi*100/ad.rda.combat1$tot.chi ad.rda.trt_prop.combat &lt;- ad.rda.combat2$pCCA$tot.chi*100/ad.rda.combat2$tot.chi # limma # conditioning on a batch effect ad.rda.limma1 &lt;- rda(ad.limma ~ group + Condition(batch), data = ad.data.design) ad.rda.limma2 &lt;- rda(ad.limma ~ batch + Condition(group), data = ad.data.design) # amount of variance ad.rda.bat_prop.limma &lt;- ad.rda.limma1$pCCA$tot.chi*100/ad.rda.limma1$tot.chi ad.rda.trt_prop.limma &lt;- ad.rda.limma2$pCCA$tot.chi*100/ad.rda.limma2$tot.chi # percentile # conditioning on a batch effect ad.rda.percentile1 &lt;- rda(ad.percentile ~ group + Condition(batch), data = ad.data.design) ad.rda.percentile2 &lt;- rda(ad.percentile ~ batch + Condition(group), data = ad.data.design) # amount of variance ad.rda.bat_prop.percentile &lt;- ad.rda.percentile1$pCCA$tot.chi*100/ad.rda.percentile1$tot.chi ad.rda.trt_prop.percentile &lt;- ad.rda.percentile2$pCCA$tot.chi*100/ad.rda.percentile2$tot.chi # SVD # conditioning on a batch effect ad.rda.svd1 &lt;- rda(ad.svd ~ group + Condition(batch), data = ad.data.design) ad.rda.svd2 &lt;- rda(ad.svd ~ batch + Condition(group), data = ad.data.design) # amount of variance ad.rda.bat_prop.svd &lt;- ad.rda.svd1$pCCA$tot.chi*100/ad.rda.svd1$tot.chi ad.rda.trt_prop.svd &lt;- ad.rda.svd2$pCCA$tot.chi*100/ad.rda.svd2$tot.chi # RUVIII # conditioning on a batch effect ad.rda.ruv1 &lt;- rda(ad.ruvIII ~ group + Condition(batch), data = ad.data.design) ad.rda.ruv2 &lt;- rda(ad.ruvIII ~ batch + Condition(group), data = ad.data.design) # amount of variance ad.rda.bat_prop.ruv &lt;- ad.rda.ruv1$pCCA$tot.chi*100/ad.rda.ruv1$tot.chi ad.rda.trt_prop.ruv &lt;- ad.rda.ruv2$pCCA$tot.chi*100/ad.rda.ruv2$tot.chi # proportion ad.rda.prop.before &lt;- c(ad.rda.bat_prop.before, ad.rda.trt_prop.before) ad.rda.prop.bmc &lt;- c(ad.rda.bat_prop.bmc, ad.rda.trt_prop.bmc) ad.rda.prop.combat &lt;- c(ad.rda.bat_prop.combat, ad.rda.trt_prop.combat) ad.rda.prop.limma &lt;- c(ad.rda.bat_prop.limma, ad.rda.trt_prop.limma) ad.rda.prop.percentile &lt;- c(ad.rda.bat_prop.percentile, ad.rda.trt_prop.percentile) ad.rda.prop.svd &lt;- c(ad.rda.bat_prop.svd, ad.rda.trt_prop.svd) ad.rda.prop.ruv &lt;- c(ad.rda.bat_prop.ruv, ad.rda.trt_prop.ruv) # merge results ad.rda.prop.val &lt;- c(ad.rda.prop.before, ad.rda.prop.bmc, ad.rda.prop.combat, ad.rda.prop.limma, ad.rda.prop.percentile, ad.rda.prop.svd, ad.rda.prop.ruv) # add batch, trt and method info ad.rda.prop &lt;- data.frame(prop = ad.rda.prop.val, prop.r = round(ad.rda.prop.val, 2), Method = rep(c(&#39;Before&#39;, &#39;BMC&#39;, &#39;ComBat&#39;, &#39;rBE&#39;, &#39;PN&#39;, &#39;SVD&#39;, &#39;RUVIII&#39;), each = 2), Type = rep(c(&#39;Batch&#39;, &#39;Treatment&#39;), 7)) # reorder levels ad.rda.prop$Method &lt;- factor(ad.rda.prop$Method, levels = unique(ad.rda.prop$Method)) ggplot(data = ad.rda.prop, aes(x = Method, y = prop, fill = Type)) + geom_bar(stat = &quot;identity&quot;, position = &#39;dodge&#39;, colour = &#39;black&#39;) + geom_text(data = ad.rda.prop, aes(Method, prop + 2.5, label = prop.r), position = position_dodge(width = 1), size = 3) + theme_bw() + labs(y = &quot;Variance explained (%)&quot;) + theme(axis.text.x = element_text(angle = 60, hjust = 1), panel.grid = element_blank(), axis.text = element_text(size = 12), axis.title = element_text(size = 15), legend.title = element_text(size = 15), legend.text = element_text(size = 12)) + scale_fill_hue(l = 40) + ylim(0,100) Similar as results from sponge data, BMC, ComBat and removeBatchEffect were more efficient at removing batch variation while preserving treatment variation. ComBat removed relatively less batch variation compared with the other two methods. Percentile normalisation did not remove enough batch variation, nor preserve enough treatment variation in AD data. RUVIII preserved enough treatment variation but did not remove enough batch variation. In sponge data, the results of BMC and removeBatchEffect are the same, while in AD data, removeBatchEffect removed less batch variation but preserved more treatment variation. This indicates some linear correlation exists between the batch and treatment effects, which might originate from the batch x treatment design. 4.2.3 PVCA PVCA can be applied as a validation method that complements pRDA, but it requires 42 OTUs minimum. Therefore, it did not apply on sponge data. # AD data ad.PVCA.score &lt;- data.frame(Interaction = NA, Batch = NA, Treatment = NA, Residuals = NA) ad.Bat_Int.factors &lt;- data.frame(Batch = ad.batch, Treatment = ad.trt) rownames(ad.Bat_Int.factors) &lt;- rownames(ad.clr) pdata &lt;- AnnotatedDataFrame(ad.Bat_Int.factors) # before ad.eset.X.before &lt;- new(&quot;ExpressionSet&quot;, exprs = t(ad.clr), phenoData = pdata) ad.pvcaObj.before &lt;- pvcaBatchAssess(ad.eset.X.before, c(&#39;Batch&#39;, &#39;Treatment&#39;), 0.6) ad.values.before &lt;- ad.pvcaObj.before$dat ad.PVCA.score[1, ] &lt;- ad.values.before # bmc ad.eset.X.bmc &lt;- new(&quot;ExpressionSet&quot;, exprs = t(ad.bmc), phenoData = pdata) ad.pvcaObj.bmc &lt;- pvcaBatchAssess(ad.eset.X.bmc, c(&#39;Batch&#39;, &#39;Treatment&#39;), 0.6) ad.values.bmc &lt;- ad.pvcaObj.bmc$dat ad.PVCA.score[2, ] &lt;- ad.values.bmc # combat ad.eset.X.combat &lt;- new(&quot;ExpressionSet&quot;, exprs = t(ad.combat), phenoData = pdata) ad.pvcaObj.combat &lt;- pvcaBatchAssess(ad.eset.X.combat, c(&#39;Batch&#39;, &#39;Treatment&#39;), 0.6) ad.values.combat &lt;- ad.pvcaObj.combat$dat ad.PVCA.score[3, ] &lt;- ad.values.combat # limma ad.eset.X.limma &lt;- new(&quot;ExpressionSet&quot;, exprs = t(ad.limma), phenoData = pdata) ad.pvcaObj.limma &lt;- pvcaBatchAssess(ad.eset.X.limma, c(&#39;Batch&#39;, &#39;Treatment&#39;), 0.6) ad.values.limma &lt;- ad.pvcaObj.limma$dat ad.PVCA.score[4, ] &lt;- ad.values.limma # PN ad.eset.X.percentile &lt;- new(&quot;ExpressionSet&quot;, exprs = t(ad.percentile), phenoData = pdata) ad.pvcaObj.percentile &lt;- pvcaBatchAssess(ad.eset.X.percentile, c(&#39;Batch&#39;, &#39;Treatment&#39;), 0.6) ad.values.percentile &lt;- ad.pvcaObj.percentile$dat ad.PVCA.score[5, ] &lt;- ad.values.percentile # svd ad.eset.X.svd &lt;- new(&quot;ExpressionSet&quot;, exprs = t(ad.svd), phenoData = pdata) ad.pvcaObj.svd &lt;- pvcaBatchAssess(ad.eset.X.svd, c(&#39;Batch&#39;, &#39;Treatment&#39;), 0.6) ad.values.svd &lt;- ad.pvcaObj.svd$dat ad.PVCA.score[6, ] &lt;- ad.values.svd # RUVIII ad.eset.X.ruv &lt;- new(&quot;ExpressionSet&quot;, exprs = t(ad.ruvIII), phenoData = pdata) ad.pvcaObj.ruv &lt;- pvcaBatchAssess(ad.eset.X.ruv, c(&#39;Batch&#39;, &#39;Treatment&#39;), 0.6) ad.values.ruv &lt;- ad.pvcaObj.ruv$dat ad.PVCA.score[7, ] &lt;- ad.values.ruv rownames(ad.PVCA.score) &lt;- c(&#39;Before&#39;, &#39;BMC&#39;, &#39;ComBat&#39;, &#39;rBE&#39;, &#39;PN&#39;, &#39;SVD&#39;, &#39;RUVIII&#39;) # merge results ad.pvca.prop.val &lt;- c(ad.PVCA.score$Batch, ad.PVCA.score$Treatment) # add batch, trt and method info ad.pvca.prop &lt;- data.frame(prop = ad.pvca.prop.val, prop.r = round(ad.pvca.prop.val, 2), Method = rep(c(&#39;Before&#39;, &#39;BMC&#39;, &#39;ComBat&#39;, &#39;rBE&#39;, &#39;PN&#39;, &#39;SVD&#39;, &#39;RUVIII&#39;), 2), Type = rep(c(&#39;Batch&#39;, &#39;Treatment&#39;), each = 7)) # reorder levels ad.pvca.prop$Method &lt;- factor(ad.pvca.prop$Method, levels = unique(ad.pvca.prop$Method)) ggplot(data = ad.pvca.prop, aes(x = Method, y = prop, fill = Type)) + geom_bar(stat = &quot;identity&quot;, position = &#39;dodge&#39;, colour = &#39;black&#39;) + geom_text(data = ad.pvca.prop, aes(Method, prop + 0.03, label = prop.r), position = position_dodge(width = 0.9), size = 3) + theme_bw() + labs(y = &quot;Weighted average proportion variance&quot;) + theme(axis.text.x = element_text(angle = 60, hjust = 1), panel.grid = element_blank(),axis.text = element_text(size = 12), axis.title = element_text(size = 15), legend.title = element_text(size = 15), legend.text = element_text(size = 12)) + scale_fill_hue(l = 40) + ylim(0,1) Proportionally, BMC, ComBat and removeBatchEffect removed more of the variance explained by batch and maintained more variance explained by treatment than other methods in AD data. 4.2.4 Silhouette coefficient Finally we assess the quality of the clusters, based on either batch or treatment information using the silhouette coefficient and the PC components. This coefficient measures how cohesive a sample is to its own cluster compared to other clusters. It has been adapted to assess the consistency of sample groups based on treatment or batch effects. The average silhouette coefficient width across all samples in one group (batch \\(\\bar{s}_{b}\\) or treatment \\(\\bar{s}_{t}\\)) is calculated and plotted here. If \\(\\bar{s}_{b}\\) is close to \\(0\\) there is no batch effect, and if \\(\\bar{s}_{t}\\) is close to \\(1\\) or \\(-1\\) there is a treatment effect. # Sponge data sponge.silh.before &lt;- calc.sil(sponge.pca.before$variates$X, y1 = sponge.batch, y2 = sponge.trt, name.y1 = &#39;Batch&#39;, name.y2 = &#39;Tissue&#39;) sponge.silh.bmc &lt;- calc.sil(sponge.pca.bmc$variates$X, y1 = sponge.batch, y2 = sponge.trt, name.y1 = &#39;Batch&#39;, name.y2 = &#39;Tissue&#39;) sponge.silh.combat &lt;- calc.sil(sponge.pca.combat$variates$X, y1 = sponge.batch, y2 = sponge.trt, name.y1 = &#39;Batch&#39;, name.y2 = &#39;Tissue&#39;) sponge.silh.limma &lt;- calc.sil(sponge.pca.limma$variates$X, y1 = sponge.batch, y2 = sponge.trt, name.y1 = &#39;Batch&#39;, name.y2 = &#39;Tissue&#39;) sponge.silh.percentile &lt;- calc.sil(sponge.pca.percentile$variates$X, y1 = sponge.batch, y2 = sponge.trt, name.y1 = &#39;Batch&#39;, name.y2 = &#39;Tissue&#39;) sponge.silh.svd &lt;- calc.sil(sponge.pca.svd$variates$X, y1 = sponge.batch, y2 = sponge.trt, name.y1 = &#39;Batch&#39;, name.y2 = &#39;Tissue&#39;) sponge.silh.plot &lt;- rbind(sponge.silh.before, sponge.silh.bmc, sponge.silh.combat, sponge.silh.limma, sponge.silh.percentile, sponge.silh.svd) sponge.silh.plot$method &lt;- c(rep(&#39;Before&#39;, nrow(sponge.silh.before)), rep(&#39;BMC&#39;, nrow(sponge.silh.bmc)), rep(&#39;ComBat&#39;, nrow(sponge.silh.combat)), rep(&#39;rBE&#39;, nrow(sponge.silh.limma)), rep(&#39;PN&#39;, nrow(sponge.silh.percentile)), rep(&#39;SVD&#39;, nrow(sponge.silh.svd)) ) sponge.silh.plot$method &lt;- factor(sponge.silh.plot$method, levels = unique(sponge.silh.plot$method)) sponge.silh.plot$Cluster &lt;- factor(sponge.silh.plot$Cluster, levels = unique(sponge.silh.plot$Cluster)) sponge.silh.plot$Type &lt;- factor(sponge.silh.plot$Type, levels = unique(sponge.silh.plot$Type)) ggplot(sponge.silh.plot, aes(x = Type, y = silh.coeff, color = Cluster, shape = Type)) + geom_point() + facet_grid(cols = vars(method)) + theme_bw() + theme(axis.text.x = element_text(angle = 60, hjust = 1), strip.text = element_text(size = 12), panel.grid = element_blank(), axis.text = element_text(size = 12), axis.title = element_text(size = 15), legend.title = element_text(size = 15), legend.text = element_text(size = 12)) + scale_color_manual(values = c(&#39;#388ECC&#39;,&#39;#F68B33&#39;,&#39;#F0E442&#39;,&#39;#D55E00&#39;)) + labs(x = &#39;Type&#39;, y = &#39;Silhouette Coefficient&#39;, name = &#39;Type&#39;) \\(\\bar{s}_{b}\\) of different batches in sponge data decreased to \\(0\\) after correction with BMC, ComBat and removeBatchEffect, while \\(\\bar{s}_{t}\\) of different tissues increased or maintained at the same level as before correction. We also calculate the silhouette coefficients for AD data. # AD data ad.silh.before &lt;- calc.sil(ad.pca.before$variates$X, y1 = ad.batch, y2 = ad.trt, name.y1 = &#39;Batch&#39;, name.y2 = &#39;Treatment&#39;) ad.silh.bmc &lt;- calc.sil(ad.pca.bmc$variates$X, y1 = ad.batch, y2 = ad.trt, name.y1 = &#39;Batch&#39;, name.y2 = &#39;Treatment&#39;) ad.silh.combat &lt;- calc.sil(ad.pca.combat$variates$X, y1 = ad.batch, y2 = ad.trt, name.y1 = &#39;Batch&#39;, name.y2 = &#39;Treatment&#39;) ad.silh.limma &lt;- calc.sil(ad.pca.limma$variates$X, y1 = ad.batch, y2 = ad.trt, name.y1 = &#39;Batch&#39;, name.y2 = &#39;Treatment&#39;) ad.silh.percentile &lt;- calc.sil(ad.pca.percentile$variates$X, y1 = ad.batch, y2 = ad.trt, name.y1 = &#39;Batch&#39;, name.y2 = &#39;Treatment&#39;) ad.silh.svd &lt;- calc.sil(ad.pca.svd$variates$X, y1 = ad.batch, y2 = ad.trt, name.y1 = &#39;Batch&#39;, name.y2 = &#39;Treatment&#39;) ad.silh.ruv &lt;- calc.sil(ad.pca.ruv$variates$X, y1 = ad.batch, y2 = ad.trt, name.y1 = &#39;Batch&#39;, name.y2 = &#39;Treatment&#39;) ad.silh.plot &lt;- rbind(ad.silh.before, ad.silh.bmc, ad.silh.combat, ad.silh.limma, ad.silh.percentile, ad.silh.svd, ad.silh.ruv) ad.silh.plot$method &lt;- c(rep(&#39;Before&#39;, nrow(ad.silh.before)), rep(&#39;BMC&#39;, nrow(ad.silh.bmc)), rep(&#39;ComBat&#39;, nrow(ad.silh.combat)), rep(&#39;rBE&#39;, nrow(ad.silh.limma)), rep(&#39;PN&#39;, nrow(ad.silh.percentile)), rep(&#39;SVD&#39;, nrow(ad.silh.svd)), rep(&#39;RUVIII&#39;, nrow(ad.silh.ruv)) ) ad.silh.plot$method &lt;- factor(ad.silh.plot$method, levels = unique(ad.silh.plot$method)) ad.silh.plot$Cluster &lt;- factor(ad.silh.plot$Cluster, levels = unique(ad.silh.plot$Cluster)) ad.silh.plot$Type &lt;- factor(ad.silh.plot$Type, levels = unique(ad.silh.plot$Type)) ggplot(ad.silh.plot, aes(x = Type, y = silh.coeff, color = Cluster, shape = Type)) + geom_point() + facet_grid(cols = vars(method)) + theme_bw() + theme(axis.text.x = element_text(angle = 60, hjust = 1), strip.text = element_text(size = 12), panel.grid = element_blank(), axis.text = element_text(size = 10), axis.title = element_text(size = 15), legend.title = element_text(size = 15), legend.text = element_text(size = 12)) + scale_color_manual(values = c(&#39;#388ECC&#39;, &#39;#F68B33&#39;, &#39;#C2C2C2&#39;, &#39;#009E73&#39;, &#39;#CC79A7&#39;, &#39;#0072B2&#39;, &#39;#999999&#39;)) + labs(x = &#39;Type&#39;, y = &#39;Silhouette Coefficient&#39;, name = &#39;Type&#39;) In AD data that includes five batches, the interpretation of the results is challenging. After correction, BMC, ComBat, removeBatchEffect, percentile normalisation and RUVIII decreased the batch silhouette coefficients for the batch dated 14/04/2016, but increased the coefficients for the other batches. Therefore it is difficult to assess the efficiency of these methods in this particular case. "],
["simu.html", "Chapter 5 Assessment of the nature of batch effects 5.1 Simulations 5.2 Real data", " Chapter 5 Assessment of the nature of batch effects 5.1 Simulations 5.1.1 Mean = 5, and unequal variance ‘Systematic’ refers to homogeneous change amongst all microbial variables (OTUs) due to having the same source of variation. We illustrate this concept in a linear model framework where batch and treatment regression coefficients are estimated simultaneously on each OTU. For a given batch effect and a given OTU, we can formulate the systematic assumption as: \\[\\beta_{j} \\sim N(\\mu,\\sigma^{2})\\] where \\(\\beta_{j}\\) is the batch regression coefficient of OTU\\(_{j}\\) (\\(j = 1,...,p\\)). Here we consider the simplest case of a linear model with one batch predictor, but this formulation could be extended to a model with multiple batch predictors where the batch regression coefficients can represent more than two batch levels. In a univariate model that tests each OTU individually, then the distribution of the batch coefficients of all OTUs is Gaussian with a mean \\(\\mu\\), and standard deviation \\(\\sigma\\). This indicates that the batch effect has a similar, though not necessarily identical, influence on all OTUs. To illustrate the type of batch effects, we simulated a set of data with 50 samples and 10,000 OTUs each, based on the simulation approach from (Gagnon-Bartsch, Jacob, and Speed 2013). The dataset with a systematic batch effect: \\(\\beta_{j} \\sim N(5,1^{2})\\) for \\(j=1,...,p\\) OTUs; \\(\\sigma_{j} \\sim N(0,2^{2})\\) for \\(j=1,...,p\\) OTUs; This variance per OTU is aimed to simulate data as realistically as possible. \\(\\beta_{ij} \\sim N(\\beta_{j}, \\sigma_{j}^{2})\\) for \\(i = 1,...,n\\) samples. # Create the simulated data m &lt;- 50 n &lt;- 10000 nc &lt;- 1000 # negative controls without treatment effects p &lt;- 1 k &lt;- 1 ctl &lt;- rep(FALSE, n) ctl[1:nc] &lt;- TRUE # treatment effect X &lt;- matrix(c(rep(0, floor(m/2)), rep(1, ceiling(m/2))), m, p) beta &lt;- matrix(rnorm(p*n, 5, 1), p, n) #treatment coefficients beta[ ,ctl] &lt;- 0 # batch effect W &lt;- as.matrix(rep(0, m), m, k) W[c(1:12,38:50), 1] &lt;- 1 alpha &lt;- matrix(rnorm(k*n, 5, 1), k, n) Y_alpha &lt;- sapply(alpha, function(alpha){rnorm(m, mean = alpha, abs(rnorm(1, mean = 0, sd = 2)))}) YY_alpha &lt;- apply(Y_alpha, 2, function(x){x*W}) epsilon &lt;- matrix(rnorm(m*n, 0, 1), m, n) Y &lt;- X%*%beta + YY_alpha + epsilon # estimate batch coefficient for each OTU w.cof &lt;- c() for(i in 1:ncol(Y)){ res &lt;- lm(Y[ ,i] ~ X + W) sum.res &lt;- summary(res) w.cof[i] &lt;- sum.res$coefficients[3,1] } par(mfrow = c(2,2)) hist(w.cof,col = &#39;gray&#39;) plot(density(w.cof)) qqnorm(w.cof) qqline(w.cof, col = &#39;red&#39;) par(mfrow = c(1,1)) The histogram, density plot and quantile–quantile plot are plotted using estimated batch regression coefficients \\(\\hat{\\beta}_{j}\\) for each OTU \\(j\\). These plots display the distribution of batch coefficients is very close to normal, indicating a systematic batch effect. 5.1.2 Mean = 0 or 5, and unequal variance Non-systematic batch effects have a heterogeneous influence on microbial variables. Using a linear model framework, as described previously, we can formulate this non-systematic assumption as: \\[ \\beta&#39;_{j} \\sim \\begin{cases} N(0,\\delta^{2}) &amp; \\text{for OTUs with no batch effect,} \\\\ N(\\mu,\\sigma^{2}) &amp; \\text{for OTUs with batch effect.} \\end{cases} \\] Therefore, the batch regression coefficients \\(\\beta&#39;_{j}\\) may follow skewed distributions with several modes. The dataset with non-systematic batch effect: \\(\\beta&#39;_{t} \\sim N(0,1^{2})\\) and \\(\\beta&#39;_{k} \\sim N(5,1^{2})\\) for \\(t=1,...,T\\) OTUs, \\(k=1,...,K\\) OTUs and \\(T=\\frac{3}{4}p\\), \\(K=\\frac{1}{4}p\\); \\(\\sigma&#39;_{j} \\sim N(0,2^{2})\\) for \\(j=1,...,p\\) OTUs; \\(\\beta&#39;_{ij} \\sim N(\\beta&#39;_{j}, \\sigma_{j}^{&#39;2})\\) for \\(i = 1,...,n\\) samples. # Create the simulated data m &lt;- 50 n &lt;- 10000 nc &lt;- 1000 # negative controls without treatment effects p &lt;- 1 k &lt;- 1 ctl &lt;- rep(FALSE, n) ctl[1:nc] &lt;- TRUE # treatment effect X &lt;- matrix(c(rep(0, floor(m/2)), rep(1, ceiling(m/2))), m, p) beta &lt;- matrix(rnorm(p*n, 5, 1), p, n) #treatment coefficients beta[ ,ctl] &lt;- 0 # batch effect W &lt;- as.matrix(rep(0, m), m, k) W[c(1:12,38:50), 1] &lt;- 1 alpha2 &lt;- matrix(sample(c(rnorm(k*(3*n/4), 0, 1),rnorm(k*(n/4), 5, 1)), n), k, n) Y_alpha2 &lt;- sapply(alpha2, function(alpha){rnorm(m, mean = alpha, sd = abs(rnorm(1, mean = 0, sd = 2)))}) YY_alpha2 &lt;- apply(Y_alpha2, 2, function(x){x*W}) epsilon &lt;- matrix(rnorm(m*n, 0, 1), m, n) Y2 &lt;- X%*%beta + YY_alpha2 + epsilon w.cof2 &lt;- c() for(i in 1:ncol(Y2)){ res &lt;- lm(Y2[ ,i] ~ X + W) sum.res &lt;- summary(res) w.cof2[i] &lt;- sum.res$coefficients[3,1] } par(mfrow = c(2,2)) hist(w.cof2, col = &#39;gray&#39;) plot(density(w.cof2)) qqnorm(w.cof2) qqline(w.cof2, col = &#39;red&#39;) par(mfrow = c(1,1)) The histogram, density plot and quantile–quantile plot are plotted using estimated batch regression coefficients \\(\\hat{\\beta}_{j}\\) for each OTU \\(j\\), showing a bi-modal distribution. This distribution indicates a non-systematic batch effect. We observed similar patterns in our real case studies, suggesting that the batch effects are mixed with multiple sources and are non-systematic (see the examples below). 5.2 Real data We also estimate the batch regression coefficients for each OTU in real datasets to assess the nature of batch effects. 5.2.1 Sponge data sponge.b.coeff &lt;- c() for(i in 1:ncol(sponge.tss.clr)){ res &lt;- lm(sponge.tss.clr[ ,i] ~ sponge.trt + sponge.batch) sum.res &lt;- summary(res) sponge.b.coeff[i] &lt;- sum.res$coefficients[3,1] } par(mfrow = c(2,2)) hist(sponge.b.coeff,col = &#39;gray&#39;) plot(density(sponge.b.coeff)) qqnorm(sponge.b.coeff) qqline(sponge.b.coeff, col=&#39;red&#39;) par(mfrow = c(1,1)) In sponge data, the histogram, density plot and quantile–quantile plot are also plotted using estimated batch regression coefficients \\(\\hat{\\beta}_{j}\\) for each OTU \\(j\\). The bi-modal distribution indicates a non-systematic batch effect, which is similar as the results from simulation with non-systematic batch effects. 5.2.2 AD data ad.b.coeff &lt;- c() ad.batch.relevel &lt;- relevel(ad.batch, &#39;01/07/2016&#39;) for(i in 1:ncol(ad.clr)){ res &lt;- lm(ad.clr[,i] ~ ad.trt + ad.batch.relevel) sum.res &lt;- summary(res) ad.b.coeff[i] &lt;- sum.res$coefficients[4,1] } par(mfrow = c(2,2)) hist(ad.b.coeff,col = &#39;gray&#39;) plot(density(ad.b.coeff)) qqnorm(ad.b.coeff) qqline(ad.b.coeff, col=&#39;red&#39;) par(mfrow = c(1,1)) We observe similar results in AD data. The distribution of estimated batch regression coefficients is not normal. The batch effects therefore are non-systematic. Bibliography "],
["bibliography.html", "Bibliography", " Bibliography "]
]
